根据笔记[如何处理发送消息的请求](如何处理发送消息的请求.md)可知，生产者发送的消息在broker端由`MessageStore`接口的`putMessage()`方法完成存储，`MessageStore`接口的默认实现类是`DefaultMessageStore`类。`MessageStore`接口定义了消息存储应该提供的方法：
```java
public interface MessageStore {
    boolean load();

    void start() throws Exception;

    void shutdown();

    void destroy();

    PutMessageResult putMessage(final MessageExtBrokerInner msg);

    PutMessageResult putMessages(final MessageExtBatch messageExtBatch);

    GetMessageResult getMessage(final String group, final String topic, final int queueId,
        final long offset, final int maxMsgNums, final MessageFilter messageFilter);

    long getMaxOffsetInQueue(final String topic, final int queueId);

    long getMinOffsetInQueue(final String topic, final int queueId);

    long getCommitLogOffsetInQueue(final String topic, final int queueId, final long consumeQueueOffset);

    long getOffsetInQueueByTime(final String topic, final int queueId, final long timestamp);

    MessageExt lookMessageByOffset(final long commitLogOffset);

    SelectMappedBufferResult selectOneMessageByOffset(final long commitLogOffset);

    SelectMappedBufferResult selectOneMessageByOffset(final long commitLogOffset, final int msgSize);

    String getRunningDataInfo();

    HashMap<String, String> getRuntimeInfo();

    long getMaxPhyOffset();

    long getMinPhyOffset();

    long getEarliestMessageTime(final String topic, final int queueId);

    long getEarliestMessageTime();

     
    long getMessageStoreTimeStamp(final String topic, final int queueId, final long consumeQueueOffset);

    long getMessageTotalInQueue(final String topic, final int queueId);

    SelectMappedBufferResult getCommitLogData(final long offset);

    boolean appendToCommitLog(final long startOffset, final byte[] data);

    void executeDeleteFilesManually();

    QueryMessageResult queryMessage(final String topic, final String key, final int maxNum, final long begin,
        final long end);

    void updateHaMasterAddress(final String newAddr);

    long slaveFallBehindMuch();

    long now();

    int cleanUnusedTopic(final Set<String> topics);

    void cleanExpiredConsumerQueue();

    boolean checkInDiskByConsumeOffset(final String topic, final int queueId, long consumeOffset);

    long dispatchBehindBytes();

    long flush();

    boolean resetWriteOffset(long phyOffset);

    long getConfirmOffset();

    void setConfirmOffset(long phyOffset);

    boolean isOSPageCacheBusy();

    long lockTimeMills();

    boolean isTransientStorePoolDeficient();

    LinkedList<CommitLogDispatcher> getDispatcherList();

    ConsumeQueue getConsumeQueue(String topic, int queueId);

    BrokerStatsManager getBrokerStatsManager();

    void handleScheduleMessageService(BrokerRole brokerRole);
}
```

上面的方法的作用在下面碰到的时候再逐个分析，这里直接开始分析消息存储的过程。rocketmq中`MessageStore`接口的实现类有两个，分别是`AbstractPluginMessageStore`抽象类和`DefaultMessageStore`类。`AbstractPluginMessageStore`抽象类只是为了支持自定义的`MessageStore`实现类，在broker启动时，会初始化`MessageStore`接口的实现类，代码在`BrokerController`类的`initialize()`方法：
```java
public boolean initialize() throws CloneNotSupportedException {
    // 略

    if (result) {
        try {
            this.messageStore =
                new DefaultMessageStore(this.messageStoreConfig, this.brokerStatsManager, this.messageArrivingListener,
                    this.brokerConfig);
            
            // 略

            //load plugin
            MessageStorePluginContext context = new MessageStorePluginContext(messageStoreConfig, brokerStatsManager, messageArrivingListener, brokerConfig);

            this.messageStore = MessageStoreFactory.build(context, this.messageStore);
            this.messageStore.getDispatcherList().addFirst(new CommitLogDispatcherCalcBitMap(this.brokerConfig, this.consumerFilterManager));
        } catch (IOException e) {
            // 略
        }
    }

    // 略
}
```

可以看到，`BrokerController`首先创建了`DefaultMessageStore`对象，之后再用`MessageStoreFactory`的`build()`方法创建一个`MessageStore`接口的实现，`build()`方法代码如下：
```java
public final static MessageStore build(MessageStorePluginContext context, MessageStore messageStore)
    throws IOException {
    String plugin = context.getBrokerConfig().getMessageStorePlugIn();
    if (plugin != null && plugin.trim().length() != 0) {
        String[] pluginClasses = plugin.split(",");
        for (int i = pluginClasses.length - 1; i >= 0; --i) {
            String pluginClass = pluginClasses[i];
            try {
                @SuppressWarnings("unchecked")
                Class<AbstractPluginMessageStore> clazz = (Class<AbstractPluginMessageStore>) Class.forName(pluginClass);
                Constructor<AbstractPluginMessageStore> construct = clazz.getConstructor(MessageStorePluginContext.class, MessageStore.class);
                messageStore = construct.newInstance(context, messageStore);
            } catch (Throwable e) {
                throw new RuntimeException(String.format(
                    "Initialize plugin's class %s not found!", pluginClass), e);
            }
        }
    }
    return messageStore;
}
```

上面的代码很简单，就是反射创建插件的实现类，并且插件的实现类要求继承自`AbstractPluginMessageStore`，下面是`AbstractPluginMessageStore`抽象类的代码：
```java
public abstract class AbstractPluginMessageStore implements MessageStore {
    protected MessageStore next = null;
    protected MessageStorePluginContext context;

    public AbstractPluginMessageStore(MessageStorePluginContext context, MessageStore next) {
        this.next = next;
        this.context = context;
    }

    @Override
    public long getEarliestMessageTime() {
        return next.getEarliestMessageTime();
    }

    @Override
    public long lockTimeMills() {
        return next.lockTimeMills();
    }

    @Override
    public boolean isOSPageCacheBusy() {
        return next.isOSPageCacheBusy();
    }

    @Override
    public boolean isTransientStorePoolDeficient() {
        return next.isTransientStorePoolDeficient();
    }

    @Override
    public boolean load() {
        return next.load();
    }

    @Override
    public void start() throws Exception {
        next.start();
    }

    @Override
    public void shutdown() {
        next.shutdown();
    }

    @Override
    public void destroy() {
        next.destroy();
    }

    @Override
    public PutMessageResult putMessage(MessageExtBrokerInner msg) {
        return next.putMessage(msg);
    }

    @Override
    public GetMessageResult getMessage(String group, String topic, int queueId, long offset,
        int maxMsgNums, final MessageFilter messageFilter) {
        return next.getMessage(group, topic, queueId, offset, maxMsgNums, messageFilter);
    }

    @Override
    public long getMaxOffsetInQueue(String topic, int queueId) {
        return next.getMaxOffsetInQueue(topic, queueId);
    }

    @Override
    public long getMinOffsetInQueue(String topic, int queueId) {
        return next.getMinOffsetInQueue(topic, queueId);
    }

    @Override
    public long getCommitLogOffsetInQueue(String topic, int queueId, long consumeQueueOffset) {
        return next.getCommitLogOffsetInQueue(topic, queueId, consumeQueueOffset);
    }

    @Override
    public long getOffsetInQueueByTime(String topic, int queueId, long timestamp) {
        return next.getOffsetInQueueByTime(topic, queueId, timestamp);
    }

    @Override
    public MessageExt lookMessageByOffset(long commitLogOffset) {
        return next.lookMessageByOffset(commitLogOffset);
    }

    @Override
    public SelectMappedBufferResult selectOneMessageByOffset(long commitLogOffset) {
        return next.selectOneMessageByOffset(commitLogOffset);
    }

    @Override
    public SelectMappedBufferResult selectOneMessageByOffset(long commitLogOffset, int msgSize) {
        return next.selectOneMessageByOffset(commitLogOffset, msgSize);
    }

    @Override
    public String getRunningDataInfo() {
        return next.getRunningDataInfo();
    }

    @Override
    public HashMap<String, String> getRuntimeInfo() {
        return next.getRuntimeInfo();
    }

    @Override
    public long getMaxPhyOffset() {
        return next.getMaxPhyOffset();
    }

    @Override
    public long getMinPhyOffset() {
        return next.getMinPhyOffset();
    }

    @Override
    public long getEarliestMessageTime(String topic, int queueId) {
        return next.getEarliestMessageTime(topic, queueId);
    }

    @Override
    public long getMessageStoreTimeStamp(String topic, int queueId, long consumeQueueOffset) {
        return next.getMessageStoreTimeStamp(topic, queueId, consumeQueueOffset);
    }

    @Override
    public long getMessageTotalInQueue(String topic, int queueId) {
        return next.getMessageTotalInQueue(topic, queueId);
    }

    @Override
    public SelectMappedBufferResult getCommitLogData(long offset) {
        return next.getCommitLogData(offset);
    }

    @Override
    public boolean appendToCommitLog(long startOffset, byte[] data) {
        return next.appendToCommitLog(startOffset, data);
    }

    @Override
    public void executeDeleteFilesManually() {
        next.executeDeleteFilesManually();
    }

    @Override
    public QueryMessageResult queryMessage(String topic, String key, int maxNum, long begin,
        long end) {
        return next.queryMessage(topic, key, maxNum, begin, end);
    }

    @Override
    public void updateHaMasterAddress(String newAddr) {
        next.updateHaMasterAddress(newAddr);
    }

    @Override
    public long slaveFallBehindMuch() {
        return next.slaveFallBehindMuch();
    }

    @Override
    public long now() {
        return next.now();
    }

    @Override
    public int cleanUnusedTopic(Set<String> topics) {
        return next.cleanUnusedTopic(topics);
    }

    @Override
    public void cleanExpiredConsumerQueue() {
        next.cleanExpiredConsumerQueue();
    }

    @Override
    public boolean checkInDiskByConsumeOffset(String topic, int queueId, long consumeOffset) {
        return next.checkInDiskByConsumeOffset(topic, queueId, consumeOffset);
    }

    @Override
    public long dispatchBehindBytes() {
        return next.dispatchBehindBytes();
    }

    @Override
    public long flush() {
        return next.flush();
    }

    @Override
    public boolean resetWriteOffset(long phyOffset) {
        return next.resetWriteOffset(phyOffset);
    }

    @Override
    public long getConfirmOffset() {
        return next.getConfirmOffset();
    }

    @Override
    public void setConfirmOffset(long phyOffset) {
        next.setConfirmOffset(phyOffset);
    }

    @Override
    public LinkedList<CommitLogDispatcher> getDispatcherList() {
        return next.getDispatcherList();
    }

    @Override
    public ConsumeQueue getConsumeQueue(String topic, int queueId) {
        return next.getConsumeQueue(topic, queueId);
    }

    @Override
    public BrokerStatsManager getBrokerStatsManager() {
        return next.getBrokerStatsManager();
    };
}
```

可以说`AbstractPluginMessageStore`类什么也没做，只是组合了`MessageStorePluginContext`对象和一个`MessageStore`接口的实现类，自定义插件可以通过继承`AbstractPluginMessageStore`类并重写若干方法实现修改`MessageStore`接口的实现类的相关逻辑的效果，而上面的`MessageStore`接口的实现类就是`DefaultMessageStore`类，rocketmq中消息存储的相关功能都是该类实现的，下面着重分析该类的实现。

`BrokerController`类首先使用到`DefaultMessageStore`的地方是其`start()`方法：
```java
public void start() throws Exception {
    if (this.messageStore != null) {
        this.messageStore.start();
    }

    // 略
}
```

所以这里先看`DefaultMessageStore`的`start()`方法：
```java
public void start() throws Exception {

    // 获取store/lock文件的独占锁以防止start方法被重复调用
    lock = lockFile.getChannel().tryLock(0, 1, false);
    if (lock == null || lock.isShared() || !lock.isValid()) {
        throw new RuntimeException("Lock failed,MQ already started");
    }

    lockFile.getChannel().write(ByteBuffer.wrap("lock".getBytes()));
    // 强制刷盘
    lockFile.getChannel().force(true);
    {
        /**
         * 1. Make sure the fast-forward messages to be truncated during the recovering according to the max physical offset of the commitlog;
         * 2. DLedger committedPos may be missing, so the maxPhysicalPosInLogicQueue maybe bigger that maxOffset returned by DLedgerCommitLog, just let it go;
         * 3. Calculate the reput offset according to the consume queue;
         * 4. Make sure the fall-behind messages to be dispatched before starting the commitlog, especially when the broker role are automatically changed.
         */
        long maxPhysicalPosInLogicQueue = commitLog.getMinOffset();
        // 遍历ConsumeQueue，获取commitlog文件里所有被放置到consumeQueue的消息的最大物理地址
        for (ConcurrentMap<Integer, ConsumeQueue> maps : this.consumeQueueTable.values()) {
            for (ConsumeQueue logic : maps.values()) {
                // getMaxPhysicOffset方法返回consumeQueue中最新的消息的commitlogOffset + 其在commitlog文件中占用的字节数
                if (logic.getMaxPhysicOffset() > maxPhysicalPosInLogicQueue) {
                    maxPhysicalPosInLogicQueue = logic.getMaxPhysicOffset();
                }
            }
        }
        if (maxPhysicalPosInLogicQueue < 0) {
            maxPhysicalPosInLogicQueue = 0;
        }
        if (maxPhysicalPosInLogicQueue < this.commitLog.getMinOffset()) {
            maxPhysicalPosInLogicQueue = this.commitLog.getMinOffset();
            /**
             * This happens in following conditions:
             * 1. If someone removes all the consumequeue files or the disk get damaged.
             * 2. Launch a new broker, and copy the commitlog from other brokers.
             *
             * All the conditions has the same in common that the maxPhysicalPosInLogicQueue should be 0.
             * If the maxPhysicalPosInLogicQueue is gt 0, there maybe something wrong.
             */
            log.warn("[TooSmallCqOffset] maxPhysicalPosInLogicQueue={} clMinOffset={}", maxPhysicalPosInLogicQueue, this.commitLog.getMinOffset());
        }
        log.info("[SetReputOffset] maxPhysicalPosInLogicQueue={} clMinOffset={} clMaxOffset={} clConfirmedOffset={}",
            maxPhysicalPosInLogicQueue, this.commitLog.getMinOffset(), this.commitLog.getMaxOffset(), this.commitLog.getConfirmOffset());
        // reputMessageService对象会不断的扫描所有的commitlog文件，不断的取出消息并交由CommitLogDispatcher对象处理，对于
        // 处理过的消息不会重复处理。为了实现不重复处理，需要保存已经处理过的消息的偏移量，下面的reputFromOffset变量的值就是这个
        // 偏移量。默认CommitLogDispatcher对象包括CommitLogDispatcherBuildConsumeQueue类，该类的作用是根据commitlog中的
        // 消息创建consumeQueue，所以可以看到上面在计算maxPhysicalPosInLogicQueue时会遍历所有的ConsumeQueue，如果消息已经
        // 在consumeQueue存在了就不需要再通过reputMessageService对象进行处理了。
        this.reputMessageService.setReputFromOffset(maxPhysicalPosInLogicQueue);
        // reputMessageService对象本质上是个线程，这里启动线程
        this.reputMessageService.start();

        /**
         *  1. Finish dispatching the messages fall behind, then to start other services.
         *  2. DLedger committedPos may be missing, so here just require dispatchBehindBytes <= 0
         */
        while (true) {
            // dispatchBehindBytes方法返回所有的commitlog中有多少字节的数据还没被reputMessageService对象处理
            if (dispatchBehindBytes() <= 0) { // 小于等于0说明全部都处理完了，此时break即可
                break;
            }
            Thread.sleep(1000); // 否则循环的sleep直到处理完
            log.info("Try to finish doing reput the messages fall behind during the starting, reputOffset={} maxOffset={} behind={}", this.reputMessageService.getReputFromOffset(), this.getMaxPhyOffset(), this.dispatchBehindBytes());
        }
        // 根据consumeQueueTable的值计算commitlog的topicQueueTable属性值，也就是计算所有的topic下的queue各自保存了多少消息的
        // consume信息
        this.recoverTopicQueueTable();
    }

    if (!messageStoreConfig.isEnableDLegerCommitLog()) {
        this.haService.start();
        this.handleScheduleMessageService(messageStoreConfig.getBrokerRole());
    }

    this.flushConsumeQueueService.start();
    this.commitLog.start();
    this.storeStatsService.start();

    // 创建store/abort文件，该文件的作用体现在load方法中
    this.createTempFile();
    // 开启若干定时任务，最重要的时定时执行cleanCommitLogService和cleanConsumeQueueService
    this.addScheduleTask();
    this.shutdown = false;
}
```

`start()`方法最重要的是启动了若干组件，开启了若干定时任务，这些组件和定时任务的作用在下面分析消息存储的过程再分析。当`start()`方法执行之后，`DefaultMessageStore`对象就可以开始保存消息了。

保存消息的方法是`DefaultMessageStore`对象的`putMessage()`方法：
```java
public PutMessageResult putMessage(MessageExtBrokerInner msg) {
    if (this.shutdown) {
        log.warn("message store has shutdown, so putMessage is forbidden");
        return new PutMessageResult(PutMessageStatus.SERVICE_NOT_AVAILABLE, null);
    }

    // slave节点的put操作直接报错，下面都是处理各种异常的情况
    if (BrokerRole.SLAVE == this.messageStoreConfig.getBrokerRole()) {
        // 记录收到的不合法写入消息请求的次数
        long value = this.printTimes.getAndIncrement();
        // 每50000次记一次日志，这样能够减少日志数量
        if ((value % 50000) == 0) {
            log.warn("message store is slave mode, so putMessage is forbidden ");
        }

        return new PutMessageResult(PutMessageStatus.SERVICE_NOT_AVAILABLE, null);
    }

    if (!this.runningFlags.isWriteable()) {
        long value = this.printTimes.getAndIncrement();
        if ((value % 50000) == 0) {
            log.warn("message store is not writeable, so putMessage is forbidden " + this.runningFlags.getFlagBits());
        }

        return new PutMessageResult(PutMessageStatus.SERVICE_NOT_AVAILABLE, null);
    } else {
        this.printTimes.set(0);
    }

    // topic太长，报错
    if (msg.getTopic().length() > Byte.MAX_VALUE) {
        log.warn("putMessage message topic length too long " + msg.getTopic().length());
        return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, null);
    }

    // 属性太长，报错
    if (msg.getPropertiesString() != null && msg.getPropertiesString().length() > Short.MAX_VALUE) {
        log.warn("putMessage message properties length too long " + msg.getPropertiesString().length());
        return new PutMessageResult(PutMessageStatus.PROPERTIES_SIZE_EXCEEDED, null);
    }

    // isOSPageCacheBusy方法默认在commitlog文件被lock超过1s时返回true
    if (this.isOSPageCacheBusy()) {
        return new PutMessageResult(PutMessageStatus.OS_PAGECACHE_BUSY, null);
    }

    // 返回当前时间
    long beginTime = this.getSystemClock().now();
    // 保存消息
    PutMessageResult result = this.commitLog.putMessage(msg);

    // 获取保存消息耗时
    long elapsedTime = this.getSystemClock().now() - beginTime;
    if (elapsedTime > 500) {
        log.warn("putMessage not in lock elapsed time(ms)={}, bodyLength={}", elapsedTime, msg.getBody().length);
    }
    // 保存耗时信息，用于统计
    this.storeStatsService.setPutMessageEntireTimeMax(elapsedTime);

    // 如果失败则增加失败次数
    if (null == result || !result.isOk()) {
        this.storeStatsService.getPutMessageFailedTimes().incrementAndGet();
    }

    return result;
}
```

上面的代码逻辑并不多，只是做了一些必要的参数校验，判断当前broker是否繁忙，如果验证通过，就执行`CommitLog`对象的`putMessage()`方法保存消息。这里值得注意的是判断broker是否繁忙的逻辑，对应的代码在`isOSPageCacheBusy()`方法：
```java
public boolean isOSPageCacheBusy() {
    // 如果commitlog文件正在被lock，则beginTimeInLock等于开始lock的时间，否则等于0
    long begin = this.getCommitLog().getBeginTimeInLock();
    long diff = this.systemClock.now() - begin;

    // 当commitlog文件未被lock时begin等于0，此时diff肯定大于10000000，直接返回false
    // this.messageStoreConfig.getOsPageCacheBusyTimeOutMills()默认返回1s，这里在diff大于1s的情况下返回busy
    return diff < 10000000
        && diff > this.messageStoreConfig.getOsPageCacheBusyTimeOutMills();
}
```

下面再看`CommitLog`对象的`putMessage()`方法是如何实现的：
```java
public PutMessageResult putMessage(final MessageExtBrokerInner msg) {
    // Set the storage time
    msg.setStoreTimestamp(System.currentTimeMillis());
    // Set the message body BODY CRC (consider the most appropriate setting
    // on the client)
    msg.setBodyCRC(UtilAll.crc32(msg.getBody()));
    // Back to Results
    AppendMessageResult result = null;

    StoreStatsService storeStatsService = this.defaultMessageStore.getStoreStatsService();

    String topic = msg.getTopic();
    int queueId = msg.getQueueId();

    final int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag());
    if (tranType == MessageSysFlag.TRANSACTION_NOT_TYPE
        || tranType == MessageSysFlag.TRANSACTION_COMMIT_TYPE) {
        // Delay Delivery
        // 如果是延迟消息
        if (msg.getDelayTimeLevel() > 0) {
            if (msg.getDelayTimeLevel() > this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel()) {
                msg.setDelayTimeLevel(this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel());
            }

            topic = ScheduleMessageService.SCHEDULE_TOPIC;
            queueId = ScheduleMessageService.delayLevel2QueueId(msg.getDelayTimeLevel());

            // Backup real topic, queueId
            MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_TOPIC, msg.getTopic());
            MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msg.getQueueId()));
            msg.setPropertiesString(MessageDecoder.messageProperties2String(msg.getProperties()));

            msg.setTopic(topic);
            msg.setQueueId(queueId);
        }
    }

    // 获取客户端地址
    InetSocketAddress bornSocketAddress = (InetSocketAddress) msg.getBornHost();
    if (bornSocketAddress.getAddress() instanceof Inet6Address) {
        msg.setBornHostV6Flag();
    }

    // storeHost默认就是当前broker地址
    InetSocketAddress storeSocketAddress = (InetSocketAddress) msg.getStoreHost();
    if (storeSocketAddress.getAddress() instanceof Inet6Address) {
        msg.setStoreHostAddressV6Flag();
    }

    long eclipsedTimeInLock = 0;

    MappedFile unlockMappedFile = null;
    // MappedFile实际上就是某个commitlog或consumeQueue文件，这里获取最新的commitlog文件
    MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile();

    // putMessageLock可能是ReentrantLock也可能是自选锁，根据配置决定，默认使用自旋锁
    putMessageLock.lock(); //spin or ReentrantLock ,depending on store config
    try {
        // 获取当前时间
        long beginLockTimestamp = this.defaultMessageStore.getSystemClock().now();
        // 记录开始lock的时间
        this.beginTimeInLock = beginLockTimestamp;

        // Here settings are stored timestamp, in order to ensure an orderly
        // global
        // 设置消息保存时间，对于某个客户端，其同步发送的消息是有响应的。如果客户端的某个线程发送消息时将某类消息（如根据业务key做
        // hash选择队列）发往同一个broker的同一个队列，那么客户端发送这类消息的顺序和broker收到消息的顺序肯定是一样的，这样在这里
        // 为消息保存系统当前时间，就能根据该时间得知客户端发送的那类消息的顺序
        msg.setStoreTimestamp(beginLockTimestamp);

        // 判断这个最新的commitlog文件是否为空或是否已经写满
        if (null == mappedFile || mappedFile.isFull()) {
            // 新建一个MappedFile文件，即新建一个commitlog文件
            mappedFile = this.mappedFileQueue.getLastMappedFile(0); // Mark: NewFile may be cause noise
        }
        // 创建失败则报错
        if (null == mappedFile) {
            log.error("create mapped file1 error, topic: " + msg.getTopic() + " clientAddr: " + msg.getBornHostString());
            beginTimeInLock = 0;
            return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, null);
        }

        // 将消息附加到commitlog文件
        result = mappedFile.appendMessage(msg, this.appendMessageCallback);
        switch (result.getStatus()) {
            case PUT_OK: // 保存成功直接返回
                break;
            case END_OF_FILE: // 如果最新的commitlog文件的剩余容量不够放置当前消息
                unlockMappedFile = mappedFile;
                // Create a new file, re-write the message
                // 新建一个commitlog文件
                mappedFile = this.mappedFileQueue.getLastMappedFile(0);
                // 新建失败则返回err
                if (null == mappedFile) {
                    // XXX: warn and notify me
                    log.error("create mapped file2 error, topic: " + msg.getTopic() + " clientAddr: " + msg.getBornHostString());
                    beginTimeInLock = 0;
                    return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, result);
                }
                // 再次附加消息到新建的commitlog文件
                result = mappedFile.appendMessage(msg, this.appendMessageCallback);
                break;
            case MESSAGE_SIZE_EXCEEDED: // 消息或其属性超出限制返回失败
            case PROPERTIES_SIZE_EXCEEDED:
                beginTimeInLock = 0;
                return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, result);
            case UNKNOWN_ERROR:
                beginTimeInLock = 0;
                return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result);
            default:
                beginTimeInLock = 0;
                return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result);
        }

        // 计算消耗的时间
        eclipsedTimeInLock = this.defaultMessageStore.getSystemClock().now() - beginLockTimestamp;
        beginTimeInLock = 0;
    } finally {
        putMessageLock.unlock();
    }

    if (eclipsedTimeInLock > 500) {
        log.warn("[NOTIFYME]putMessage in lock cost time(ms)={}, bodyLength={} AppendMessageResult={}", eclipsedTimeInLock, msg.getBody().length, result);
    }

    // 如果附加消息成功并且没有创建新的commitlog文件则unlockMappedFile为null，否则为上一个commitlog文件，这里执行和mlock相反
    // 的操作munlock，使得操作系统能够回收和swap上一个commitlog文件
    if (null != unlockMappedFile && this.defaultMessageStore.getMessageStoreConfig().isWarmMapedFileEnable()) {
        this.defaultMessageStore.unlockMappedFile(unlockMappedFile);
    }

    // 运行到这说明附加成功了
    PutMessageResult putMessageResult = new PutMessageResult(PutMessageStatus.PUT_OK, result);

    // Statistics
    // 添加统计信息
    storeStatsService.getSinglePutMessageTopicTimesTotal(msg.getTopic()).incrementAndGet();
    storeStatsService.getSinglePutMessageTopicSizeTotal(topic).addAndGet(result.getWroteBytes());

    // 同步或异步刷盘
    handleDiskFlush(result, putMessageResult, msg);
    // 如果使用的是SYNC_MASTER同步更新slave，则等待slave更新消息
    handleHA(result, putMessageResult, msg);

    return putMessageResult;
}
```

`putMessage()`方法做了不少事，首先是对事务消息的处理，相关分析在笔记[如何实现事务消息](如何实现事务消息.md)，这里不再赘述。`putMessage()`方法还设置了一些传入的消息的属性，包括存储时间、bodyCRC、sysFlag等，这些信息最后都会和消息本体一块落盘。处理完消息对象后，`putMessage()`方法调用`this.mappedFileQueue.getLastMappedFile()`语句创建`MappedFile`对象，这个`MappedFile`对象对于消息存储的实现起到了最关键的作用，commitlog文件和consumeQueue文件都用到了`MappedFile`类，这里首先看rocketmq中关于commitlog的设计：

commitlog文件是消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容，消息内容不是定长的。单个文件大小默认1G，文件名长度为20位，左边补零，剩余为起始偏移量，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。消息主要是顺序写入日志文件，当文件满了，写入下一个文件。

上面提到的00000000000000000000和00000000001073741824文件在实际broker的存储路径默认是`~/store/commitlog`文件夹，broker运行时，随着消息不断的写入，该文件夹下会陆续创建若干文件，文件名的格式如上所示。rocketmq将commitlog文件夹的这种工作机制抽象了出来，提供了`CommitLog`对象表示commitlog文件夹，`CommitLog`对象持有`MappedFileQueue`对象，`MappedFileQueue`对象表示commitlog文件夹下的所有文件，通过`MappedFileQueue`对象，可以很方便的对commitlog文件夹内的文件进行操作，如创建和获取`MappedFile`对象、获取文件的最大和最小偏移量等。`MappedFile`对象表示的是某个commitlog文件夹内的文件，如上面的00000000000000000000和00000000001073741824文件，对commitlog内某个文件数据的读取与写入就是通过`MappedFile`对象实现的。`DefaultMessageStore`类实现消息存储就是通过`CommitLog`对象，而消息消费的过程和消息存储类似，对应的是`ConsumeQueue`类，这一块的分析在笔记[如何实现消息消费](../client/如何实现消息消费.md)，这里不再赘述。

下面来看看`CommitLog`的`putMessage()`方法是如何通过`MappedFile`对象保存消息的。首先获取`MappedFile`对象的过程：
```java
public PutMessageResult putMessage(final MessageExtBrokerInner msg) {
    // 略

    MappedFile unlockMappedFile = null;
    // MappedFile实际上就是某个commitlog或consumeQueue文件，这里获取最新的commitlog文件
    MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile();

    // putMessageLock可能是ReentrantLock也可能是自选锁，根据配置决定，默认使用自旋锁
    putMessageLock.lock(); //spin or ReentrantLock ,depending on store config
    try {
        // 略

        // 判断这个最新的commitlog文件是否为空或是否已经写满
        if (null == mappedFile || mappedFile.isFull()) {
            // 新建一个MappedFile文件，即新建一个commitlog文件
            mappedFile = this.mappedFileQueue.getLastMappedFile(0); // Mark: NewFile may be cause noise
        }
        // 创建失败则报错
        if (null == mappedFile) {
            log.error("create mapped file1 error, topic: " + msg.getTopic() + " clientAddr: " + msg.getBornHostString());
            beginTimeInLock = 0;
            return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, null);
        }

        // 将消息附加到commitlog文件
        result = mappedFile.appendMessage(msg, this.appendMessageCallback);
    }
    // 略
}
```

首先通过`this.mappedFileQueue.getLastMappedFile()`语句获取最新的`MappedFile`对象，`MappedFile`对象文件名称由起始偏移量组成，所以这里相当于获取偏移量最大的`MappedFile`对象，`MappedFileQueue`对象的`getLastMappedFile()`方法代码：
```java
public MappedFile getLastMappedFile() {
    MappedFile mappedFileLast = null;

    while (!this.mappedFiles.isEmpty()) {
        try {
            mappedFileLast = this.mappedFiles.get(this.mappedFiles.size() - 1);
            break;
        } catch (IndexOutOfBoundsException e) {
            //continue;
        } catch (Exception e) {
            log.error("getLastMappedFile has exception.", e);
            break;
        }
    }

    return mappedFileLast;
}
```

上面用到的`mappedFiles`是`MappedFileQueue`对象中用于保存所有commitlog文件夹下文件对应的`MappedFile`对象的`CopyOnWriteArrayList`，最新的`MappedFile`对象就是list的最后一个元素。

在获取到`MappedFile`对象后，判断了该对象是否为空和是否满了，如果为空说明commitlog文件夹下没有文件，或者如果不为空但是文件已经写满了，这两种情况都需要创建一个新的文件，即创建一个新的`MappedFile`对象，这里先看如何判断`MappedFile`对象是否满了，对应的`isFull()`方法：
```java
public boolean isFull() {
    return this.fileSize == this.wrotePosition.get();
}
```

`wrotePosition`变量保存的是消息写入到`MappedFile`对象对应的文件的位置（实际上只是写入到buffer，还未commit和flush），所以当文件大小和写入位置相等时，就是`MappedFile`对象写满了。

下面来看`this.mappedFileQueue.getLastMappedFile(0)`语句是如何创建`MappedFile`对象的，对应的方法如下：
```java
public MappedFile getLastMappedFile(final long startOffset) {
    return getLastMappedFile(startOffset, true);
}

public MappedFile getLastMappedFile(final long startOffset, boolean needCreate) {
    long createOffset = -1;
    MappedFile mappedFileLast = getLastMappedFile();

    // 如果最新的MappedFile文件为空，则从startOffset开始，下面的计算方式保证createOffset等于mappedFileSize的整数倍
    if (mappedFileLast == null) {
        createOffset = startOffset - (startOffset % this.mappedFileSize);
    }

    // 如果MappedFile不为空并且已经满了则获取下一个创建的MappedFile的起始offset
    if (mappedFileLast != null && mappedFileLast.isFull()) {
        createOffset = mappedFileLast.getFileFromOffset() + this.mappedFileSize;
    }

    if (createOffset != -1 && needCreate) {
        // 根据offset获取即将创建的MappedFile文件的路径
        String nextFilePath = this.storePath + File.separator + UtilAll.offset2FileName(createOffset);
        // 预创建下一个文件的文件名称
        String nextNextFilePath = this.storePath + File.separator
            + UtilAll.offset2FileName(createOffset + this.mappedFileSize);
        MappedFile mappedFile = null;

        // 如果allocateMappedFileService不为空则使用allocateMappedFileService创建MappedFile。否则直接new一个
        if (this.allocateMappedFileService != null) {
            mappedFile = this.allocateMappedFileService.putRequestAndReturnMappedFile(nextFilePath,
                nextNextFilePath, this.mappedFileSize);
        } else {
            try {
                mappedFile = new MappedFile(nextFilePath, this.mappedFileSize);
            } catch (IOException e) {
                log.error("create mappedFile exception", e);
            }
        }

        if (mappedFile != null) {
            // 如果mappedFiles为空表示刚创建的MappedFile对象是第一个MappedFile文件
            if (this.mappedFiles.isEmpty()) {
                mappedFile.setFirstCreateInQueue(true);
            }
            this.mappedFiles.add(mappedFile);
        }

        return mappedFile;
    }

    return mappedFileLast;
}
```

上面的方法在最新的`MappedFile`对象不存在或`MappedFile`对象已经满的情况下都会执行创建`MappedFile`对象的逻辑，代码如下：
```java
// 根据offset获取即将创建的MappedFile文件的路径
String nextFilePath = this.storePath + File.separator + UtilAll.offset2FileName(createOffset);
// 预创建下一个文件的文件名称
String nextNextFilePath = this.storePath + File.separator
    + UtilAll.offset2FileName(createOffset + this.mappedFileSize);
MappedFile mappedFile = null;

// 如果allocateMappedFileService不为空则使用allocateMappedFileService创建MappedFile。否则直接new一个
if (this.allocateMappedFileService != null) {
    mappedFile = this.allocateMappedFileService.putRequestAndReturnMappedFile(nextFilePath,
        nextNextFilePath, this.mappedFileSize);
} else {
    try {
        mappedFile = new MappedFile(nextFilePath, this.mappedFileSize);
    } catch (IOException e) {
        log.error("create mappedFile exception", e);
    }
}
```

首先根据offset创建文件名，如00000000001073741824，另外除了即将创建了文件名，还创建了下一个需要被创建的文件名，如当前需要创建的文件为00000000001073741824，则`nextNextFilePath`是00000000002147483648，这么做的目的是为了预创建commitlog文件，这个在下面的分析就能看到。

在`allocateMappedFileService`对象不为空时创建`MappedFile`对象的任务由它完成，默认情况下`allocateMappedFileService`指向`AllocateMappedFileService`对象，所以默认情况下`MappedFile`对象由`AllocateMappedFileService`完成，其`putRequestAndReturnMappedFile()`方法代码如下：
```java
public MappedFile putRequestAndReturnMappedFile(String nextFilePath, String nextNextFilePath, int fileSize) {
    // 默认要创建nextFilePath和nextNextFilePath两个文件，所以这里默认假设允许创建2个请求
    int canSubmitRequests = 2;
    // 如果开启了"读写分离"的模式
    if (this.messageStore.getMessageStoreConfig().isTransientStorePoolEnable()) {
        // 如果开启了在无写buffer可用的情况下的快速失败配置
        if (this.messageStore.getMessageStoreConfig().isFastFailIfNoBufferInStorePool()
            && BrokerRole.SLAVE != this.messageStore.getMessageStoreConfig().getBrokerRole()) { //if broker is slave, don't fast fail even no buffer in pool
            // 可用的buffer数量减去等待创建的请求数量就是真正可用的buffer数量
            canSubmitRequests = this.messageStore.getTransientStorePool().availableBufferNums() - this.requestQueue.size();
        }
    }

    // AllocateRequest对象表示创建新文件的请求
    AllocateRequest nextReq = new AllocateRequest(nextFilePath, fileSize);
    // 将请求保存到map，以路径为key，request为值，如果nextFilePath在map中存在则nextPutOK为false，表示指定路径已经创建过request了
    // 由于下面的预创建机制，即预创建nextNextFilePath文件，所以除了第一次运行，基本上这里的nextPutOK都是false，这样每次调用
    // putRequestAndReturnMappedFile方法都不需要等待MappedFile文件创建完成，因为在上一次putRequestAndReturnMappedFile方法
    // 执行时就已经创建了
    boolean nextPutOK = this.requestTable.putIfAbsent(nextFilePath, nextReq) == null;

    if (nextPutOK) {
        // 如果允许创建的请求数量小于等于0则返回
        if (canSubmitRequests <= 0) {
            log.warn("[NOTIFYME]TransientStorePool is not enough, so create mapped file error, " +
                "RequestQueueSize : {}, StorePoolSize: {}", this.requestQueue.size(), this.messageStore.getTransientStorePool().availableBufferNums());
            // 不能创建则删除请求记录
            this.requestTable.remove(nextFilePath);
            return null;
        }
        // request保存到阻塞队列中，供mmapOperation方法执行创建文件的操作
        boolean offerOK = this.requestQueue.offer(nextReq);
        if (!offerOK) {
            log.warn("never expected here, add a request to preallocate queue failed");
        }
        canSubmitRequests--;
    }

    // nextNextFilePath为下一个将被创建的commitlog文件路径
    AllocateRequest nextNextReq = new AllocateRequest(nextNextFilePath, fileSize);
    boolean nextNextPutOK = this.requestTable.putIfAbsent(nextNextFilePath, nextNextReq) == null;
    // 这里相当于预创建下一个MappedFile的意思
    if (nextNextPutOK) {
        if (canSubmitRequests <= 0) {
            log.warn("[NOTIFYME]TransientStorePool is not enough, so skip preallocate mapped file, " +
                "RequestQueueSize : {}, StorePoolSize: {}", this.requestQueue.size(), this.messageStore.getTransientStorePool().availableBufferNums());
            this.requestTable.remove(nextNextFilePath);
        } else {
            boolean offerOK = this.requestQueue.offer(nextNextReq);
            if (!offerOK) {
                log.warn("never expected here, add a request to preallocate queue failed");
            }
        }
    }

    if (hasException) {
        log.warn(this.getServiceName() + " service has exception. so return null");
        return null;
    }

    // requestTable保存了所有创建MappedFile文件的请求，上面的代码在允许创建文件的情况下会将MappedFile文件的AllocateRequest对象
    // 添加到requestQueue这个阻塞队列中，AllocateMappedFileService类本身也是个线程，其run方法会不断的调用mmapOperation方法从
    // requestQueue获取请求并执行创建MappedFile文件的逻辑，创建完成后将创建结果更新AllocateRequest对象，这里获取nextFilePath对
    // 应的AllocateRequest对象，通过countDownLatch等待mmapOperation方法创建完nextFilePath文件
    AllocateRequest result = this.requestTable.get(nextFilePath);
    try {
        if (result != null) {
            // 等待commitlog文件创建完成
            boolean waitOK = result.getCountDownLatch().await(waitTimeOut, TimeUnit.MILLISECONDS);
            if (!waitOK) {
                log.warn("create mmap timeout " + result.getFilePath() + " " + result.getFileSize());
                return null;
            } else {
                // 创建成功删除AllocateRequest对象
                this.requestTable.remove(nextFilePath);
                // 返回被创建的MappedFile文件，此时requestTable中还存在nextNextFilePath对应的AllocateRequest对象，这里
                // 不需要等待nextNextFilePath创建完成，因为nextNextFilePath文件是预创建的，还没有被使用，等到需要时再从
                // requestTable获取对应的AllocateRequest对象并await即可
                return result.getMappedFile();
            }
        } else {
            log.error("find preallocate mmap failed, this never happen");
        }
    } catch (InterruptedException e) {
        log.warn(this.getServiceName() + " service has exception. ", e);
    }

    return null;
}
```

`putRequestAndReturnMappedFile()`方法没有指向真正的创建逻辑，而是为传入的文件名创建`AllocateRequest`对象，表示创建文件请求，之后将`AllocateRequest`对象保存到`requestQueue`队列中，最后通过`AllocateRequest`对象的`CountDownLatch`等待创建完成，真正执行创建逻辑的代码肯定在别的方法中，这个后面会分析，这里先看`putRequestAndReturnMappedFile()`方法做的其他工作。`putRequestAndReturnMappedFile()`方法首先用`canSubmitRequests`变量表示能够创建的请求数量，也就是`AllocateRequest`对象的数量，之后根据`MessageStoreConfig`的配置判断是否对`canSubmitRequests`变量进行更新，也就是是否限制能够创建的请求的数量，首先看`isTransientStorePoolEnable()`方法：
```java
public boolean isTransientStorePoolEnable() {
    return transientStorePoolEnable && FlushDiskType.ASYNC_FLUSH == getFlushDiskType()
        && BrokerRole.SLAVE != getBrokerRole();
}
```

上面的`transientStorePoolEnable`变量为true并且当前broker为异步刷盘且为master的情况下`isTransientStorePoolEnable()`方法返回true，`transientStorePoolEnable`变量为true时表示开启“读写分离”模式，这个“读写分离”模式的作用是，`MappedFile`对象初始化时除了创建一个通过mmap创建而来的`MappedByteBuffer`对象外，还会从broker的buffer池中申请一个堆外内存`ByteBuffer`，由`writeBuffer`属性持有。当需要写入数据时，不是直接调用写数据到`MappedByteBuffer`对象，而是写入到`writeBuffer`，`writeBuffer`中的数据由后台线程`CommitLof`的内部类`CommitRealTimeService`执行commit操作写入到`FileChannel`对象（创建`MappedByteBuffer`的那个`FileChannel`对象），当`MappedFile`对象close时会将`writeBuffer`还给broker的buffer池。默认`transientStorePoolEnable`变量为false，此时写入数据时，直接写入到`MappedByteBuffer`对象而不是`FileChannel`。关于broker中的buffer池如何创建堆外内存、为什么需要“读写分离”模式以及为什么“读写分离”模式是将`writeBuffer`的数据写入到`FileChannel`而不是`MappedByteBuffer`，可以看笔记[transientStorePoolEnable属性解析](transientStorePoolEnable属性解析.md)，下面继续来看`putRequestAndReturnMappedFile()`方法对可申请的`MappedFile`对象的限制：
```java
if (this.messageStore.getMessageStoreConfig().isTransientStorePoolEnable()) {
    // 如果开启了在无写buffer可用的情况下的快速失败配置
    if (this.messageStore.getMessageStoreConfig().isFastFailIfNoBufferInStorePool()
        && BrokerRole.SLAVE != this.messageStore.getMessageStoreConfig().getBrokerRole()) { //if broker is slave, don't fast fail even no buffer in pool
        // 可用的buffer数量减去等待创建的请求数量就是真正可用的buffer数量
        canSubmitRequests = this.messageStore.getTransientStorePool().availableBufferNums() - this.requestQueue.size();
    }
}
```

如果上面的if条件都满足，则更新可申请的`MappedFile`对象数量为broker的buffer池中可用的buffer数量减去等待创建的`MappedFile`对象的数量的值。

上面说了`putRequestAndReturnMappedFile()`方法的实现。现在来看看真正创建`MappedFile`对象的方法。`AllocateMappedFileService`类继承自`ServiceThread`类，其`run()`方法首先为：
```java
public void run() {
    log.info(this.getServiceName() + " service started");

    while (!this.isStopped() && this.mmapOperation()) {

    }
    log.info(this.getServiceName() + " service end");
}
```

不间断的调用`mmapOperation()`方法，而`mmapOperation()`就是真正创建`MappedFile`对象的方法，下面是该方法的代码：
```java
private boolean mmapOperation() {
    boolean isSuccess = false;
    AllocateRequest req = null;
    try {
        // 从阻塞队列获取一个创建文件请求
        req = this.requestQueue.take();
        AllocateRequest expectedRequest = this.requestTable.get(req.getFilePath());
        if (null == expectedRequest) {
            log.warn("this mmap request expired, maybe cause timeout " + req.getFilePath() + " "
                + req.getFileSize());
            return true;
        }
        if (expectedRequest != req) {
            log.warn("never expected here,  maybe cause timeout " + req.getFilePath() + " "
                + req.getFileSize() + ", req:" + req + ", expectedRequest:" + expectedRequest);
            return true;
        }

        if (req.getMappedFile() == null) {
            // 开始创建commitlog文件
            long beginTime = System.currentTimeMillis();

            MappedFile mappedFile;
            // 如果开启了"读写分离"模式
            if (messageStore.getMessageStoreConfig().isTransientStorePoolEnable()) {
                try {
                    // spi，如果在META-INF/services目录下有org.apache.rocketmq.store.MappedFile文件，则以该文件中的
                    // 类为MappedFile实现类
                    mappedFile = ServiceLoader.load(MappedFile.class).iterator().next();
                    mappedFile.init(req.getFilePath(), req.getFileSize(), messageStore.getTransientStorePool());
                } catch (RuntimeException e) {
                    log.warn("Use default implementation.");
                    // 找不到实现类时使用默认实现
                    mappedFile = new MappedFile(req.getFilePath(), req.getFileSize(), messageStore.getTransientStorePool());
                }
            } else {
                mappedFile = new MappedFile(req.getFilePath(), req.getFileSize());
            }

            // 计算当前时间和beginTime的时间差
            long elapsedTime = UtilAll.computeElapsedTimeMilliseconds(beginTime);
            if (elapsedTime > 10) {
                int queueSize = this.requestQueue.size();
                log.warn("create mappedFile spent time(ms) " + elapsedTime + " queue size " + queueSize
                    + " " + req.getFilePath() + " " + req.getFileSize());
            }

            // pre write mappedFile
            // 如果开启预热MapedFile，则使用mlock方法锁住MapedFile文件对应的内存地址，并使用madvise方法建议操作系统预读MapedFile文件
            // 到内存
            if (mappedFile.getFileSize() >= this.messageStore.getMessageStoreConfig()
                .getMappedFileSizeCommitLog()
                &&
                this.messageStore.getMessageStoreConfig().isWarmMapedFileEnable()) {
                mappedFile.warmMappedFile(this.messageStore.getMessageStoreConfig().getFlushDiskType(),
                    this.messageStore.getMessageStoreConfig().getFlushLeastPagesWhenWarmMapedFile());
            }

            req.setMappedFile(mappedFile);
            this.hasException = false;
            isSuccess = true;
        }
    } catch (InterruptedException e) {
        log.warn(this.getServiceName() + " interrupted, possibly by shutdown.");
        this.hasException = true;
        return false;
    } catch (IOException e) {
        log.warn(this.getServiceName() + " service has exception. ", e);
        this.hasException = true;
        if (null != req) {
            requestQueue.offer(req);
            try {
                Thread.sleep(1);
            } catch (InterruptedException ignored) {
            }
        }
    } finally {
        if (req != null && isSuccess)
            req.getCountDownLatch().countDown();
    }
    return true;
}
```

`mmapOperation()`方法逻辑很简单，从`requestQueue`中获取需要创建的`MappedFile`对象的请求，再根据是否开启“读写分离”模式调用不同的`MappedFile`类的构造函数创建`MappedFile`对象。`mmapOperation()`方法在创建`MappedFile`对象后，如果开启了预热文件的配置，则会执行`MappedFile`对象的`warmMappedFile()`方法预热文件，该方法代码：
```java
public void warmMappedFile(FlushDiskType type, int pages) {
    long beginTime = System.currentTimeMillis();
    // mappedByteBuffer为MappedFile文件的MappedByteBuffer
    ByteBuffer byteBuffer = this.mappedByteBuffer.slice();
    int flush = 0;
    long time = System.currentTimeMillis();
    for (int i = 0, j = 0; i < this.fileSize; i += MappedFile.OS_PAGE_SIZE, j++) {
        /*
         mappedByteBuffer是通过mmap返回的，mmap将一个磁盘文件（比如一个commitlog文件，或者是consumeQueue文件）映射到内存中，
         但是开始时并不是直接把磁盘文件里的数据给读取到内存，mmap执行完后，并没有任何的数据拷贝操作，磁盘文件还是停留在那里，mmap
         首先做的是把磁盘文件的地址和用户进程私有空间的虚拟内存地址进行一个映射（mmap在进行文件映射的时候，一般有大小限制，在
         1.5GB~2GB之间，所以rocketmq才让commitlog单个文件在1GB，consumeQueue文件在5.72MB）。当需要对文件进行读写时，比如要写入
         消息到commitlog文件，需要先获取commitlog文件的MappedByteBuffer对象，该对象就代表着被映射的虚拟内存地址。对MappedByteBuffer
         执行写入操作时，数据会直接进入PageCache中，然后过一段时间之后，由os的线程异步刷入磁盘中。当要读取数据时，同样通过MappedByteBuffer
         对象读取数据，读取时会判断数据是否在pageCache里，如果在的话，就可以直接从PageCache里读取了。如果pageCache里没有要读的数据，
         那么此时就会从磁盘文件里加载数据到pageCache中，而且pageCache在加载数据的时候，还会将加载的数据块临近的其他数据块也一起加载
         到PageCache中。
         这里向mappedByteBuffer添加空数据，相当于初始化数据，下面的mlock方法会预读mappedByteBuffer对应的内存，所以这里初始化数据是
         为了这个？
         */
        byteBuffer.put(i, (byte) 0);
        // force flush when flush disk type is sync
        // 如果是同步刷盘，则每pages次循环刷一次盘
        if (type == FlushDiskType.SYNC_FLUSH) {
            if ((i / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE) >= pages) {
                flush = i;
                mappedByteBuffer.force();
            }
        }

        // prevent gc
        // 这是啥操作？网上看到的解释是通过Thread.sleep(0)实现线程切换，给gc线程更多的机会允许，这样就能减少之后一次gc允许的时间
        // 不是很理解这种做法，源自https://stackoverflow.com/questions/53284031/why-thread-sleep0-can-prevent-gc-in-rocketmq
        if (j % 1000 == 0) {
            log.info("j={}, costTime={}", j, System.currentTimeMillis() - time);
            time = System.currentTimeMillis();
            try {
                Thread.sleep(0);
            } catch (InterruptedException e) {
                log.error("Interrupted", e);
            }
        }
    }

    // force flush when prepare load finished
    if (type == FlushDiskType.SYNC_FLUSH) {
        log.info("mapped file warm-up done, force to disk, mappedFile={}, costTime={}",
            this.getFileName(), System.currentTimeMillis() - beginTime);
        mappedByteBuffer.force();
    }
    log.info("mapped file warm-up done. mappedFile={}, costTime={}", this.getFileName(),
        System.currentTimeMillis() - beginTime);

    // 锁住mappedByteBuffer对应的内存段防止被操作系统swap掉，调用madvise预读mappedByteBuffer对应的内存段
    this.mlock();
}
```

`warmMappedFile()`方法首先填充了初始化数据到`mappedByteBuffer`，之后调用`mlock()`方法锁住内存，该方法代码：
```java
public void mlock() {
    final long beginTime = System.currentTimeMillis();
    // 返回内存中的起始地址
    final long address = ((DirectBuffer) (this.mappedByteBuffer)).address();
    Pointer pointer = new Pointer(address);
    {
        // mlock操作能够锁住内存防止内存段被操作系统swap掉，这里锁住mappedByteBuffer对应的整个文件大小的内存，这样对文件的读写操作就是
        // 基于内存的操作，大大提高了读写效率，并且由于使用的内存不由JVM管理，所以也减少了垃圾回收的时间
        int ret = LibC.INSTANCE.mlock(pointer, new NativeLong(this.fileSize));
        log.info("mlock {} {} {} ret = {} time consuming = {}", address, this.fileName, this.fileSize, ret, System.currentTimeMillis() - beginTime);
    }

    {
        // madvise操作是向操作系统提出关于指定内存段的建议，这里的madv_willneed建议表示对应的内存段可能马上就要被访问，希望操作
        // 系统能够预读一些这段内存的页面
        int ret = LibC.INSTANCE.madvise(pointer, new NativeLong(this.fileSize), LibC.MADV_WILLNEED);
        log.info("madvise {} {} {} ret = {} time consuming = {}", address, this.fileName, this.fileSize, ret, System.currentTimeMillis() - beginTime);
    }
}
```

以上是创建`MappedFile`对象的过程，再回到`CommitLog`对象的`putMessage()`方法，在获取到`MappedFile`对象后，`putMessage()`方法的执行逻辑：
```java
public PutMessageResult putMessage(final MessageExtBrokerInner msg) {
    // 略

    MappedFile unlockMappedFile = null;
    // MappedFile实际上就是某个commitlog或consumeQueue文件，这里获取最新的commitlog文件
    MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile();

    // putMessageLock可能是ReentrantLock也可能是自选锁，根据配置决定，默认使用自旋锁
    putMessageLock.lock(); //spin or ReentrantLock ,depending on store config
    try {
        // 略

        // 将消息附加到commitlog文件
        result = mappedFile.appendMessage(msg, this.appendMessageCallback);
        switch (result.getStatus()) {
            case PUT_OK: // 保存成功直接返回
                break;
            case END_OF_FILE: // 如果最新的commitlog文件的剩余容量不够放置当前消息
                unlockMappedFile = mappedFile;
                // Create a new file, re-write the message
                // 新建一个commitlog文件
                mappedFile = this.mappedFileQueue.getLastMappedFile(0);
                // 新建失败则返回err
                if (null == mappedFile) {
                    // XXX: warn and notify me
                    log.error("create mapped file2 error, topic: " + msg.getTopic() + " clientAddr: " + msg.getBornHostString());
                    beginTimeInLock = 0;
                    return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, result);
                }
                // 再次附加消息到新建的commitlog文件
                result = mappedFile.appendMessage(msg, this.appendMessageCallback);
                break;
            case MESSAGE_SIZE_EXCEEDED: // 消息或其属性超出限制返回失败
            case PROPERTIES_SIZE_EXCEEDED:
                beginTimeInLock = 0;
                return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, result);
            case UNKNOWN_ERROR:
                beginTimeInLock = 0;
                return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result);
            default:
                beginTimeInLock = 0;
                return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result);
        }

        // 计算消耗的时间
        eclipsedTimeInLock = this.defaultMessageStore.getSystemClock().now() - beginLockTimestamp;
        beginTimeInLock = 0;
    } finally {
        putMessageLock.unlock();
    }

    if (eclipsedTimeInLock > 500) {
        log.warn("[NOTIFYME]putMessage in lock cost time(ms)={}, bodyLength={} AppendMessageResult={}", eclipsedTimeInLock, msg.getBody().length, result);
    }

    // 如果附加消息成功并且没有创建新的commitlog文件则unlockMappedFile为null，否则为上一个commitlog文件，这里执行和mlock相反
    // 的操作munlock，使得操作系统能够回收和swap上一个commitlog文件
    if (null != unlockMappedFile && this.defaultMessageStore.getMessageStoreConfig().isWarmMapedFileEnable()) {
        this.defaultMessageStore.unlockMappedFile(unlockMappedFile);
    }

    // 运行到这说明附加成功了
    PutMessageResult putMessageResult = new PutMessageResult(PutMessageStatus.PUT_OK, result);

    // Statistics
    // 添加统计信息
    storeStatsService.getSinglePutMessageTopicTimesTotal(msg.getTopic()).incrementAndGet();
    storeStatsService.getSinglePutMessageTopicSizeTotal(topic).addAndGet(result.getWroteBytes());

    // 同步或异步刷盘
    handleDiskFlush(result, putMessageResult, msg);
    // 如果使用的是SYNC_MASTER同步更新slave，则等待slave更新消息
    handleHA(result, putMessageResult, msg);

    return putMessageResult;
}
```

获取到`MappedFile`对象后，首先调用其`appendMessage()`方法保存消息，下面来看看该方法的实现：
```java
public AppendMessageResult appendMessage(final MessageExtBrokerInner msg, final AppendMessageCallback cb) {
    return appendMessagesInner(msg, cb);
}

public AppendMessageResult appendMessagesInner(final MessageExt messageExt, final AppendMessageCallback cb) {
    assert messageExt != null;
    assert cb != null;

    // 获取上次写入的位置
    int currentPos = this.wrotePosition.get();

    if (currentPos < this.fileSize) {
        // 如果开启了"读写分离"模式则使用写buffer，也就是writeBuffer，否则使用内存映射的buffer
        // slice方法返回一个新的ByteBuffer对象，该对象和原ByteBuffer指向同一个buffer，但是新建
        // 的ByteBuffer的position等于0，capacity等于原ByteBuffer的capacity - position，也就是
        // slice返回剩余可写入的buffer
        ByteBuffer byteBuffer = writeBuffer != null ? writeBuffer.slice() : this.mappedByteBuffer.slice();
        // 每次创建ByteBuffer对象时，都是通过上面slice方法返回的，虽然新建的ByteBuffer对象和上面的writeBuffer或mappedByteBuffer
        // 使用的是同一个缓存区，但是新建的ByteBuffer对象的position和capacity等属性和上面两个ByteBuffer对象互不影响，所以每次都
        // 使用slice并在不操作上面两个ByteBuffer对象的情况下，上面两个ByteBuffer对象的position和capacity属性始终不变，分别等于
        // 0和MappedFile文件大小。因此，slice出来的新的ByteBuffer对象的position也始终是0，而capacity也等于MappedFile文件大小。
        // 这里将position设置为之前写入的位置，下面会从该位置继续写入数据
        byteBuffer.position(currentPos);
        AppendMessageResult result;
        if (messageExt instanceof MessageExtBrokerInner) {
            result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos, (MessageExtBrokerInner) messageExt);
        } else if (messageExt instanceof MessageExtBatch) {
            result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos, (MessageExtBatch) messageExt);
        } else {
            return new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR);
        }
        // 更新写入的位置
        this.wrotePosition.addAndGet(result.getWroteBytes());
        // 更新写入的时间
        this.storeTimestamp = result.getStoreTimestamp();
        return result;
    }
    log.error("MappedFile.appendMessage return null, wrotePosition: {} fileSize: {}", currentPos, this.fileSize);
    return new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR);
}
```

`appendMessagesInner()`方法在笔记[transientStorePoolEnable属性解析](transientStorePoolEnable属性解析.md)中有介绍，根据是否开启“读写分离”模式选择用于保存消息的buffer，真正保存消息的方法是`AppendMessageCallback`接口的`doAppend()`方法，默认实现在`DefaultAppendMessageCallback`类，该方法代码：
```java
// maxBlank参数为commitlog当前剩余的容量
public AppendMessageResult doAppend(final long fileFromOffset, final ByteBuffer byteBuffer, final int maxBlank,
    final MessageExtBrokerInner msgInner) {
    // STORETIMESTAMP + STOREHOSTADDRESS + OFFSET <br>

    // PHY OFFSET
    // 获取当前开始写入数据的位置
    long wroteOffset = fileFromOffset + byteBuffer.position();

    int sysflag = msgInner.getSysFlag();

    // ipv4和ipv6长度分别为4和16，同时都还需要保存4个字节的端口（端口是int值）
    int bornHostLength = (sysflag & MessageSysFlag.BORNHOST_V6_FLAG) == 0 ? 4 + 4 : 16 + 4;
    // 同上，这里保存的是存储commitlog文件的机器的ip，一般为当前broker的ip地址
    int storeHostLength = (sysflag & MessageSysFlag.STOREHOSTADDRESS_V6_FLAG) == 0 ? 4 + 4 : 16 + 4;
    // 新建buffer
    ByteBuffer bornHostHolder = ByteBuffer.allocate(bornHostLength);
    ByteBuffer storeHostHolder = ByteBuffer.allocate(storeHostLength);

    // 设置position为0，设置limit为传入的长度
    this.resetByteBuffer(storeHostHolder, storeHostLength);
    String msgId;
    if ((sysflag & MessageSysFlag.STOREHOSTADDRESS_V6_FLAG) == 0) {
        // msgId由storeHost和当前msg的起始写入位置组成
        msgId = MessageDecoder.createMessageId(this.msgIdMemory, msgInner.getStoreHostBytes(storeHostHolder), wroteOffset);
    } else {
        msgId = MessageDecoder.createMessageId(this.msgIdV6Memory, msgInner.getStoreHostBytes(storeHostHolder), wroteOffset);
    }

    // Record ConsumeQueue information
    // 清空keyBuilder
    keyBuilder.setLength(0);
    // msgKey由topic-queueId组成
    keyBuilder.append(msgInner.getTopic());
    keyBuilder.append('-');
    keyBuilder.append(msgInner.getQueueId());
    String key = keyBuilder.toString();
    Long queueOffset = CommitLog.this.topicQueueTable.get(key);
    if (null == queueOffset) {
        queueOffset = 0L;
        CommitLog.this.topicQueueTable.put(key, queueOffset);
    }

    // Transaction messages that require special handling
    final int tranType = MessageSysFlag.getTransactionValue(msgInner.getSysFlag());
    switch (tranType) {
        // Prepared and Rollback message is not consumed, will not enter the
        // consumer queuec
        case MessageSysFlag.TRANSACTION_PREPARED_TYPE: // 事务消息中的半消息
        case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE: // 事务回滚消息
            queueOffset = 0L;
            break;
        case MessageSysFlag.TRANSACTION_NOT_TYPE: // 非事务消息
        case MessageSysFlag.TRANSACTION_COMMIT_TYPE: // 事务提交消息
        default:
            break;
    }

    /**
     * Serialize message
     */
    // 获取属性
    final byte[] propertiesData =
        msgInner.getPropertiesString() == null ? null : msgInner.getPropertiesString().getBytes(MessageDecoder.CHARSET_UTF8);

    final int propertiesLength = propertiesData == null ? 0 : propertiesData.length;

    // 属性长度不能超过32767个字节
    if (propertiesLength > Short.MAX_VALUE) {
        log.warn("putMessage message properties length too long. length={}", propertiesData.length);
        return new AppendMessageResult(AppendMessageStatus.PROPERTIES_SIZE_EXCEEDED);
    }

    // 获取topic
    final byte[] topicData = msgInner.getTopic().getBytes(MessageDecoder.CHARSET_UTF8);
    final int topicLength = topicData.length;

    // 获取消息体
    final int bodyLength = msgInner.getBody() == null ? 0 : msgInner.getBody().length;

    /*
     计算消息总大小，结果如calMsgLength方法注释所说：
     final int msgLen = 4 //TOTALSIZE
    + 4 //MAGICCODE
    + 4 //BODYCRC
    + 4 //QUEUEID
    + 4 //FLAG
    + 8 //QUEUEOFFSET
    + 8 //PHYSICALOFFSET
    + 4 //SYSFLAG
    + 8 //BORNTIMESTAMP
    + bornhostLength //BORNHOST
    + 8 //STORETIMESTAMP
    + storehostAddressLength //STOREHOSTADDRESS
    + 4 //RECONSUMETIMES
    + 8 //Prepared Transaction Offset
    + 4 + (bodyLength > 0 ? bodyLength : 0) //BODY
    + 1 + topicLength //TOPIC
    + 2 + (propertiesLength > 0 ? propertiesLength : 0) //propertiesLength
    + 0;
     */
    final int msgLen = calMsgLength(msgInner.getSysFlag(), bodyLength, topicLength, propertiesLength);

    // Exceeds the maximum message
    // 超过最大长度则报错，默认4M
    if (msgLen > this.maxMessageSize) {
        CommitLog.log.warn("message size exceeded, msg total size: " + msgLen + ", msg body size: " + bodyLength
            + ", maxMessageSize: " + this.maxMessageSize);
        return new AppendMessageResult(AppendMessageStatus.MESSAGE_SIZE_EXCEEDED);
    }

    // Determines whether there is sufficient free space
    // maxBlank实际上就是commitlog文件的剩余容量，这里判断容量是不是够
    if ((msgLen + END_FILE_MIN_BLANK_LENGTH) > maxBlank) {
        this.resetByteBuffer(this.msgStoreItemMemory, maxBlank);
        // 1 TOTALSIZE
        this.msgStoreItemMemory.putInt(maxBlank);
        // 2 MAGICCODE
        this.msgStoreItemMemory.putInt(CommitLog.BLANK_MAGIC_CODE);
        // 3 The remaining space may be any value
        // Here the length of the specially set maxBlank
        final long beginTimeMills = CommitLog.this.defaultMessageStore.now();
        // 将maxBlank和CommitLog.BLANK_MAGIC_CODE写入到commitlog文件
        byteBuffer.put(this.msgStoreItemMemory.array(), 0, maxBlank);
        return new AppendMessageResult(AppendMessageStatus.END_OF_FILE, wroteOffset, maxBlank, msgId, msgInner.getStoreTimestamp(),
            queueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills);
    }

    // Initialization of storage space
    this.resetByteBuffer(msgStoreItemMemory, msgLen);
    // 开始填充消息内容
    // 1 TOTALSIZE
    this.msgStoreItemMemory.putInt(msgLen);
    // 2 MAGICCODE
    this.msgStoreItemMemory.putInt(CommitLog.MESSAGE_MAGIC_CODE);
    // 3 BODYCRC
    this.msgStoreItemMemory.putInt(msgInner.getBodyCRC());
    // 4 QUEUEID
    this.msgStoreItemMemory.putInt(msgInner.getQueueId());
    // 5 FLAG
    this.msgStoreItemMemory.putInt(msgInner.getFlag());
    // 6 QUEUEOFFSET
    this.msgStoreItemMemory.putLong(queueOffset);
    // 7 PHYSICALOFFSET
    // 消息在commitlog文件的offset
    this.msgStoreItemMemory.putLong(fileFromOffset + byteBuffer.position());
    // 8 SYSFLAG
    this.msgStoreItemMemory.putInt(msgInner.getSysFlag());
    // 9 BORNTIMESTAMP
    // msgInner对象的创建时间，即broker收到消息的时间
    this.msgStoreItemMemory.putLong(msgInner.getBornTimestamp());
    // 10 BORNHOST
    // 客户端IP地址
    this.resetByteBuffer(bornHostHolder, bornHostLength);
    this.msgStoreItemMemory.put(msgInner.getBornHostBytes(bornHostHolder));
    // 11 STORETIMESTAMP
    // 开始执行putMessage方法的时间
    this.msgStoreItemMemory.putLong(msgInner.getStoreTimestamp());
    // 12 STOREHOSTADDRESS
    // 一般为当前broker的IP地址
    this.resetByteBuffer(storeHostHolder, storeHostLength);
    this.msgStoreItemMemory.put(msgInner.getStoreHostBytes(storeHostHolder));
    // 13 RECONSUMETIMES
    this.msgStoreItemMemory.putInt(msgInner.getReconsumeTimes());
    // 14 Prepared Transaction Offset
    this.msgStoreItemMemory.putLong(msgInner.getPreparedTransactionOffset());
    // 15 BODY
    this.msgStoreItemMemory.putInt(bodyLength);
    if (bodyLength > 0)
        this.msgStoreItemMemory.put(msgInner.getBody());
    // 16 TOPIC
    this.msgStoreItemMemory.put((byte) topicLength);
    this.msgStoreItemMemory.put(topicData);
    // 17 PROPERTIES
    this.msgStoreItemMemory.putShort((short) propertiesLength);
    if (propertiesLength > 0)
        this.msgStoreItemMemory.put(propertiesData);

    final long beginTimeMills = CommitLog.this.defaultMessageStore.now();
    // Write messages to the queue buffer
    byteBuffer.put(this.msgStoreItemMemory.array(), 0, msgLen);

    // 创建放置成功对象
    AppendMessageResult result = new AppendMessageResult(AppendMessageStatus.PUT_OK, wroteOffset, msgLen, msgId,
        msgInner.getStoreTimestamp(), queueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills);

    switch (tranType) {
        case MessageSysFlag.TRANSACTION_PREPARED_TYPE:
        case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:
            break;
        case MessageSysFlag.TRANSACTION_NOT_TYPE:
        case MessageSysFlag.TRANSACTION_COMMIT_TYPE:
            // The next update ConsumeQueue information
            CommitLog.this.topicQueueTable.put(key, ++queueOffset);
            break;
        default:
            break;
    }
    return result;
}
```

`doAppend()`方法的逻辑并不复杂，根据`MessageExtBrokerInner`对象的数据解析出消息的信息和消息本体并保存到buffer中，值得注意的是如果commitlog文件的剩余容量小于当前需要保存的消息时的处理：
```java
// Determines whether there is sufficient free space
// maxBlank实际上就是commitlog文件的剩余容量，这里判断容量是不是够
if ((msgLen + END_FILE_MIN_BLANK_LENGTH) > maxBlank) {
    this.resetByteBuffer(this.msgStoreItemMemory, maxBlank);
    // 1 TOTALSIZE
    this.msgStoreItemMemory.putInt(maxBlank);
    // 2 MAGICCODE
    this.msgStoreItemMemory.putInt(CommitLog.BLANK_MAGIC_CODE);
    // 3 The remaining space may be any value
    // Here the length of the specially set maxBlank
    final long beginTimeMills = CommitLog.this.defaultMessageStore.now();
    // 将maxBlank和CommitLog.BLANK_MAGIC_CODE写入到commitlog文件
    byteBuffer.put(this.msgStoreItemMemory.array(), 0, maxBlank);
    return new AppendMessageResult(AppendMessageStatus.END_OF_FILE, wroteOffset, maxBlank, msgId, msgInner.getStoreTimestamp(),
        queueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills);
}
```

判断消息体的长度加上`END_FILE_MIN_BLANK_LENGTH`的值是否大于commitlog文件的剩余容量，这里加上`END_FILE_MIN_BLANK_LENGTH`的值是因为当commitlog文件容量不够时，rocketmq会向commitlog文件填充不够放置的消息的长度和`CommitLog.BLANK_MAGIC_CODE`两个int值，也就是上面if语句内的逻辑，这两个值长度就等于`END_FILE_MIN_BLANK_LENGTH`的值：
```java
class DefaultAppendMessageCallback implements AppendMessageCallback {
    // File at the end of the minimum fixed length empty
    // 每次写入消息时，要保重消息的大小加上这里的值小于等于commitlog文件的剩余大小，之所以加上这里的值，是因为当commitlog文件的剩余
    // 大小不足以保存一个消息时，doAppend方法会填充两个int值，并返回END_OF_FILE的结果，这里的4 + 4就是为了保证在commitlog文件放
    // 不下一个消息时doAppend方法能够填充两个int值
    private static final int END_FILE_MIN_BLANK_LENGTH = 4 + 4;

    // 略
}
```

当commitlog文件容量不够时，`doAppend()`方法返回`AppendMessageStatus.END_OF_FILE`状态的结果，下面是`CommitLog`类的`putMessage()`方法对这种状态的结果的处理逻辑
```java
result = mappedFile.appendMessage(msg, this.appendMessageCallback);
switch (result.getStatus()) {
    case PUT_OK: // 保存成功直接返回
        break;
    case END_OF_FILE: // 如果最新的commitlog文件的剩余容量不够放置当前消息
        unlockMappedFile = mappedFile;
        // Create a new file, re-write the message
        // 新建一个commitlog文件
        mappedFile = this.mappedFileQueue.getLastMappedFile(0);
        // 新建失败则返回err
        if (null == mappedFile) {
            // XXX: warn and notify me
            log.error("create mapped file2 error, topic: " + msg.getTopic() + " clientAddr: " + msg.getBornHostString());
            beginTimeInLock = 0;
            return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, result);
        }
        // 再次附加消息到新建的commitlog文件
        result = mappedFile.appendMessage(msg, this.appendMessageCallback);
        break;
    case MESSAGE_SIZE_EXCEEDED: // 消息或其属性超出限制返回失败
    case PROPERTIES_SIZE_EXCEEDED:
        beginTimeInLock = 0;
        return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, result);
    case UNKNOWN_ERROR:
        beginTimeInLock = 0;
        return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result);
    default:
        beginTimeInLock = 0;
        return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result);
}
```

逻辑很简单，当commitlog文件容量不够时，再新建一个`MappedFile`对象并保存消息。

上面是消息保存到buffer中的逻辑，由于rocketmq使用了mmap进行消息保存，所以消息真正落盘需要等待操作系统将pageCache中的数据保存到磁盘，或者rocketmq主动调用flush方法强制刷盘。下面来看rocketmq的刷盘逻辑。执行刷盘逻辑的类是`FlushRealTimeService`或者`GroupCommitService`，对应的初始化在`CommitLog`类的构造函数：
```java
public CommitLog(final DefaultMessageStore defaultMessageStore) {
    this.mappedFileQueue = new MappedFileQueue(defaultMessageStore.getMessageStoreConfig().getStorePathCommitLog(),
        defaultMessageStore.getMessageStoreConfig().getMappedFileSizeCommitLog(), defaultMessageStore.getAllocateMappedFileService());
    this.defaultMessageStore = defaultMessageStore;

    // 同步刷盘还是异步刷盘，使用不同的FlushCommitLogService实现类处理
    if (FlushDiskType.SYNC_FLUSH == defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) {
        this.flushCommitLogService = new GroupCommitService();
    } else {
        this.flushCommitLogService = new FlushRealTimeService();
    }

    // 略
}
```

在分析这两个类的实现之前，先看`CommitLog`对象的`putMessage()`方法：
```java
public PutMessageResult putMessage(final MessageExtBrokerInner msg) {
    // 略

    // 同步或异步刷盘
    handleDiskFlush(result, putMessageResult, msg);
    // 如果使用的是SYNC_MASTER同步更新slave，则等待slave更新消息
    handleHA(result, putMessageResult, msg);

    return putMessageResult;
}
```

`putMessage()`方法在消息保存成功后执行`handleDiskFlush()`方法处理刷盘逻辑，该方法代码如下：
```java
public void handleDiskFlush(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) {
    // Synchronization flush
    if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) {
        final GroupCommitService service = (GroupCommitService) this.flushCommitLogService;
        // 是否需要等待数据落盘才认为消息发送成功，默认为true
        if (messageExt.isWaitStoreMsgOK()) {
            GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes());
            service.putRequest(request);
            // 同步等待刷盘完成
            boolean flushOK = request.waitForFlush(this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout());
            if (!flushOK) {
                log.error("do groupcommit, wait for flush failed, topic: " + messageExt.getTopic() + " tags: " + messageExt.getTags()
                    + " client address: " + messageExt.getBornHostString());
                putMessageResult.setPutMessageStatus(PutMessageStatus.FLUSH_DISK_TIMEOUT);
            }
        } else {
            // 如果不需要等待则直接唤醒GroupCommitService，GroupCommitService会直接执行flush操作
            service.wakeup();
        }
    }
    // Asynchronous flush
    else {
        // 异步刷盘的情况下如果开启"读写分离"模式则唤醒commitLogService，commitLogService在commit之后会唤醒flushCommitLogService
        // 执行flush，否则直接唤醒flushCommitLogService
        if (!this.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) {
            flushCommitLogService.wakeup();
        } else {
            commitLogService.wakeup();
        }
    }
}
```

如果配置为异步刷盘，则使用的是`FlushRealTimeService`类，该类的实现如下：
```java
abstract class FlushCommitLogService extends ServiceThread {
    protected static final int RETRY_TIMES_OVER = 10;
}

class FlushRealTimeService extends FlushCommitLogService {
    private long lastFlushTimestamp = 0;
    private long printTimes = 0;

    public void run() {
        CommitLog.log.info(this.getServiceName() + " service started");

        while (!this.isStopped()) {
            // 是否以固定的时间执行flush，默认为false
            boolean flushCommitLogTimed = CommitLog.this.defaultMessageStore.getMessageStoreConfig().isFlushCommitLogTimed();

            // flush的时间间隔
            int interval = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushIntervalCommitLog();
            // 该变量表示至少多少页（默认每页4K）的数据没有被flush时执行flush，当flushPhysicQueueLeastPages为0时不考虑多少页没有
            // 被flush，直接执行flush
            int flushPhysicQueueLeastPages = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushCommitLogLeastPages();

            // 多少时间忽略未被flush的数据量执行一次flush
            int flushPhysicQueueThoroughInterval =
                CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushCommitLogThoroughInterval();

            // 表示是否打印未被flush的数据量到日志
            boolean printFlushProgress = false;

            // Print flush progress
            long currentTimeMillis = System.currentTimeMillis();
            if (currentTimeMillis >= (this.lastFlushTimestamp + flushPhysicQueueThoroughInterval)) {
                this.lastFlushTimestamp = currentTimeMillis;
                flushPhysicQueueLeastPages = 0;
                // 每10次打印1次
                printFlushProgress = (printTimes++ % 10) == 0;
            }

            try {
                // 如果是固定时间执行flush则用sleep
                if (flushCommitLogTimed) {
                    Thread.sleep(interval);
                } else {
                    // 否则用waitForRunning方法等待，这样在wait超时之前，如果CommitRealTimeService对象commit了新的数据，则
                    // 这里会被唤醒
                    this.waitForRunning(interval);
                }

                if (printFlushProgress) {
                    this.printFlushProgress();
                }

                long begin = System.currentTimeMillis();
                CommitLog.this.mappedFileQueue.flush(flushPhysicQueueLeastPages);
                long storeTimestamp = CommitLog.this.mappedFileQueue.getStoreTimestamp();
                if (storeTimestamp > 0) {
                    CommitLog.this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimestamp);
                }
                long past = System.currentTimeMillis() - begin;
                if (past > 500) {
                    log.info("Flush data to disk costs {} ms", past);
                }
            } catch (Throwable e) {
                CommitLog.log.warn(this.getServiceName() + " service has exception. ", e);
                this.printFlushProgress();
            }
        }

        // Normal shutdown, to ensure that all the flush before exit
        boolean result = false;
        for (int i = 0; i < RETRY_TIMES_OVER && !result; i++) {
            result = CommitLog.this.mappedFileQueue.flush(0);
            CommitLog.log.info(this.getServiceName() + " service shutdown, retry " + (i + 1) + " times " + (result ? "OK" : "Not OK"));
        }

        this.printFlushProgress();

        CommitLog.log.info(this.getServiceName() + " service end");
    }

    @Override
    public String getServiceName() {
        return FlushRealTimeService.class.getSimpleName();
    }

    private void printFlushProgress() {
        // CommitLog.log.info("how much disk fall behind memory, "
        // + CommitLog.this.mappedFileQueue.howMuchFallBehind());
    }

    @Override
    public long getJointime() {
        return 1000 * 60 * 5;
    }
}
```

上面的实现和`CommitRealTimeService`类的实现差不多，根据配置在一定时间后调用`CommitLog.this.mappedFileQueue.flush(flushPhysicQueueLeastPages)`语句执行刷新操作，或者在其他线程唤醒后执行。对于刷新操作，和commit操作差不多，代码如下：
```java
public boolean flush(final int flushLeastPages) {
    boolean result = true;
    // 获取flush的位置所在的mappedFile
    MappedFile mappedFile = this.findMappedFileByOffset(this.flushedWhere, this.flushedWhere == 0);
    if (mappedFile != null) {
        long tmpTimeStamp = mappedFile.getStoreTimestamp();
        // flush当前文件
        int offset = mappedFile.flush(flushLeastPages);
        long where = mappedFile.getFileFromOffset() + offset;
        // 更新最新的flush位置
        result = where == this.flushedWhere;
        this.flushedWhere = where;
        if (0 == flushLeastPages) {
            this.storeTimestamp = tmpTimeStamp;
        }
    }

    return result;
}

public int flush(final int flushLeastPages) {
    // 判断是否需要执行flush，当flushLeastPages大于0时，至少有flushLeastPages页（默认每页4K）的数据没有flush的时候
    // isAbleToFlush方法返回true，当flushLeastPages等于0时，如果存在未被flush的数据则返回true
    if (this.isAbleToFlush(flushLeastPages)) {
        if (this.hold()) {
            // 获取写入数据的位置，当前flushedPosition的值和写入数据的位置之间的数据就是未被flush的数据
            int value = getReadPosition();

            try {
                //We only append data to fileChannel or mappedByteBuffer, never both.
                if (writeBuffer != null || this.fileChannel.position() != 0) {
                    this.fileChannel.force(false);
                } else {
                    this.mappedByteBuffer.force();
                }
            } catch (Throwable e) {
                log.error("Error occurred when force data to disk.", e);
            }

            this.flushedPosition.set(value);
            this.release();
        } else {
            log.warn("in flush, hold failed, flush offset = " + this.flushedPosition.get());
            this.flushedPosition.set(getReadPosition());
        }
    }
    return this.getFlushedPosition();
}
```

简单来说就是在达到一定数据量后执行`force()`方法强制刷盘。

下面再看同步刷盘配置下刷盘逻辑，对应的实现类是`GroupCommitService`。在同步刷盘的情况下`handleDiskFlush()`方法会添加`GroupCommitRequest`到`GroupCommitService`并等待`GroupCommitService`刷盘完成，下面是`GroupCommitService`的实现：
```java
class GroupCommitService extends FlushCommitLogService {
    private volatile List<GroupCommitRequest> requestsWrite = new ArrayList<GroupCommitRequest>();
    private volatile List<GroupCommitRequest> requestsRead = new ArrayList<GroupCommitRequest>();

    public synchronized void putRequest(final GroupCommitRequest request) {
        // requestsWrite对应的是一个刷盘请求
        synchronized (this.requestsWrite) {
            this.requestsWrite.add(request);
        }
        if (hasNotified.compareAndSet(false, true)) {
            // 唤醒在run方法的waitForRunning处等待的线程，以执行doCommit方法，注意waitForRunning方法
            // 在waitPoint.await等待完成后，会在finally中执行onWaitEnd方法，当前类的onWaitEnd方法会执行
            // swapRequests方法
            waitPoint.countDown(); // notify
        }
    }

    private void swapRequests() {
        List<GroupCommitRequest> tmp = this.requestsWrite;
        this.requestsWrite = this.requestsRead;
        this.requestsRead = tmp;
    }

    private void doCommit() {
        synchronized (this.requestsRead) {
            if (!this.requestsRead.isEmpty()) {
                // 遍历所有的flush请求
                for (GroupCommitRequest req : this.requestsRead) {
                    // There may be a message in the next file, so a maximum of
                    // two times the flush
                    boolean flushOK = false;
                    // 最多重试两次
                    for (int i = 0; i < 2 && !flushOK; i++) {
                        flushOK = CommitLog.this.mappedFileQueue.getFlushedWhere() >= req.getNextOffset();

                        if (!flushOK) {
                            CommitLog.this.mappedFileQueue.flush(0);
                        }
                    }

                    // 唤醒正在handleDiskFlush方法的waitForFlush处等待的线程
                    req.wakeupCustomer(flushOK);
                }

                // 更新flush成功的时间
                long storeTimestamp = CommitLog.this.mappedFileQueue.getStoreTimestamp();
                if (storeTimestamp > 0) {
                    CommitLog.this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimestamp);
                }

                this.requestsRead.clear();
            } else {
                // Because of individual messages is set to not sync flush, it
                // will come to this process
                // 如果handleDiskFlush方法的messageExt.isWaitStoreMsgOK()判断为false，表示不需要等待flush完成，handleDiskFlush
                // 方法会直接唤醒GroupCommitService，此时requestsRead中没有flush请求，这里就直接执行flush操作
                CommitLog.this.mappedFileQueue.flush(0);
            }
        }
    }

    public void run() {
        CommitLog.log.info(this.getServiceName() + " service started");

        while (!this.isStopped()) {
            try {
                this.waitForRunning(10);
                this.doCommit();
            } catch (Exception e) {
                CommitLog.log.warn(this.getServiceName() + " service has exception. ", e);
            }
        }

        // Under normal circumstances shutdown, wait for the arrival of the
        // request, and then flush
        try {
            Thread.sleep(10);
        } catch (InterruptedException e) {
            CommitLog.log.warn("GroupCommitService Exception, ", e);
        }

        synchronized (this) {
            this.swapRequests();
        }

        this.doCommit();

        CommitLog.log.info(this.getServiceName() + " service end");
    }

    @Override
    protected void onWaitEnd() {
        // 交换requestsWrite和requestsRead，这么做的目的是避免产生锁竞争，可以发现putRequest方法会锁住requestsWrite并向其写入数据，
        // 而doCommit方法会锁住requestsRead并从其中读取数据，这样使用两个list，就能够实现doCommit方法执行时其他线程还能够执行
        // putRequest方法向requestsWrite写入数据
        this.swapRequests();
    }

    @Override
    public String getServiceName() {
        return GroupCommitService.class.getSimpleName();
    }

    @Override
    public long getJointime() {
        return 1000 * 60 * 5;
    }
}
```

`GroupCommitService`类的逻辑简单来说就是获取flush请求并执行flush，`GroupCommitService`类的实现需要关注的地方在于其对保存请求的list做了优化，如`onWaitEnd()`方法注释所说，当`handleDiskFlush()`方法调用`GroupCommitService`对象的`putRequest()`方法后，会锁住`GroupCommitService`对象的`requestsWrite`列表并向该列表写入flush请求，之后调用`waitPoint.countDown()`语句唤醒正在`GroupCommitService`对象的`run()`方法的`this.waitForRunning(10)`语句等待的线程，`waitForRunning()`方法代码如下：
```java
protected void waitForRunning(long interval) {
    if (hasNotified.compareAndSet(true, false)) {
        this.onWaitEnd();
        return;
    }

    //entry to wait
    waitPoint.reset();

    try {
        waitPoint.await(interval, TimeUnit.MILLISECONDS);
    } catch (InterruptedException e) {
        log.error("Interrupted", e);
    } finally {
        hasNotified.set(false);
        this.onWaitEnd();
    }
}
```

被唤醒后，会执行`onWaitEnd()`方法，`GroupCommitService`对象的`onWaitEnd()`方法实现：
```java
@Override
protected void onWaitEnd() {
    // 交换requestsWrite和requestsRead，这么做的目的是避免产生锁竞争，可以发现putRequest方法会锁住requestsWrite并向其写入数据，
    // 而doCommit方法会锁住requestsRead并从其中读取数据，这样使用两个list，就能够实现doCommit方法执行时其他线程还能够执行
    // putRequest方法向requestsWrite写入数据
    this.swapRequests();
}

private void swapRequests() {
    List<GroupCommitRequest> tmp = this.requestsWrite;
    this.requestsWrite = this.requestsRead;
    this.requestsRead = tmp;
}
```

如注释所说，`GroupCommitService`类提供了两个列表，对flush请求的添加和处理进行了优化，避免了`doCommit()`方法在flush期间其他线程无法获取列表的锁的情况。

在消息保存到commitlog文件后，还需要更新消息对应的队列的consumequeue文件和消息对应的index文件，下面分析这两个文件的数据是如何被写入的。

`DefaultMessageStore`类的构造函数会初始化`ReputMessageService`类：
```java
public DefaultMessageStore(final MessageStoreConfig messageStoreConfig, final BrokerStatsManager brokerStatsManager,
    final MessageArrivingListener messageArrivingListener, final BrokerConfig brokerConfig) throws IOException {
    // 略...

    this.reputMessageService = new ReputMessageService();

    // 略...
}
```

`DefaultMessageStore`类在启动时会启动`ReputMessageService`对象，`DefaultMessageStore`类的`start()`方法：
```java
public void start() throws Exception {
    // 略...

    {
        long maxPhysicalPosInLogicQueue = commitLog.getMinOffset();
        // 遍历ConsumeQueue，获取commitlog文件里所有被放置到consumeQueue的消息的最大物理地址
        for (ConcurrentMap<Integer, ConsumeQueue> maps : this.consumeQueueTable.values()) {
            for (ConsumeQueue logic : maps.values()) {
                // getMaxPhysicOffset方法返回consumeQueue中最新的消息的commitlogOffset + 其在commitlog文件中占用的字节数
                if (logic.getMaxPhysicOffset() > maxPhysicalPosInLogicQueue) {
                    maxPhysicalPosInLogicQueue = logic.getMaxPhysicOffset();
                }
            }
        }
        if (maxPhysicalPosInLogicQueue < 0) {
            maxPhysicalPosInLogicQueue = 0;
        }
        if (maxPhysicalPosInLogicQueue < this.commitLog.getMinOffset()) {
            maxPhysicalPosInLogicQueue = this.commitLog.getMinOffset();
            log.warn("[TooSmallCqOffset] maxPhysicalPosInLogicQueue={} clMinOffset={}", maxPhysicalPosInLogicQueue, this.commitLog.getMinOffset());
        }
        log.info("[SetReputOffset] maxPhysicalPosInLogicQueue={} clMinOffset={} clMaxOffset={} clConfirmedOffset={}",
            maxPhysicalPosInLogicQueue, this.commitLog.getMinOffset(), this.commitLog.getMaxOffset(), this.commitLog.getConfirmOffset());
        // reputMessageService对象会不断的扫描所有的commitlog文件，不断的取出消息并交由CommitLogDispatcher对象处理，对于
        // 处理过的消息不会重复处理。为了实现不重复处理，需要保存已经处理过的消息的偏移量，下面的reputFromOffset变量的值就是这个
        // 偏移量。默认CommitLogDispatcher对象包括CommitLogDispatcherBuildConsumeQueue类，该类的作用是根据commitlog中的
        // 消息创建consumeQueue，所以可以看到上面在计算maxPhysicalPosInLogicQueue时会遍历所有的ConsumeQueue，如果消息已经
        // 在consumeQueue存在了就不需要再通过reputMessageService对象进行处理了。
        this.reputMessageService.setReputFromOffset(maxPhysicalPosInLogicQueue);
        // reputMessageService对象本质上是个线程，这里启动线程
        this.reputMessageService.start();

        // 略...
    }

    // 略...
}
```

`ReputMessageService`类继承`ServiceThread`类，所以该类是个线程，其`run()`方法：
```java
@Override
public void run() {
    DefaultMessageStore.log.info(this.getServiceName() + " service started");

    while (!this.isStopped()) {
        try {
            Thread.sleep(1);
            this.doReput();
        } catch (Exception e) {
            DefaultMessageStore.log.warn(this.getServiceName() + " service has exception. ", e);
        }
    }

    DefaultMessageStore.log.info(this.getServiceName() + " service end");
}

```

定时执行`doReput()`方法，下面再看看`doReput()`方法的实现：
```java
private void doReput() {
    // 如果已经被ReputMessageService类处理的位移小于commitlog文件的最小位移，则修正reputFromOffset的值
    if (this.reputFromOffset < DefaultMessageStore.this.commitLog.getMinOffset()) {
        log.warn("The reputFromOffset={} is smaller than minPyOffset={}, this usually indicate that the dispatch behind too much and the commitlog has expired.",
            this.reputFromOffset, DefaultMessageStore.this.commitLog.getMinOffset());
        this.reputFromOffset = DefaultMessageStore.this.commitLog.getMinOffset();
    }
    // 当reputFromOffset小于commitlog文件保存的消息的最大位移时
    for (boolean doNext = true; this.isCommitLogAvailable() && doNext; ) {

        // duplicationEnable默认为false，这里用到的confirmOffset属性不知道啥意思，没有更新该属性的地方
        if (DefaultMessageStore.this.getMessageStoreConfig().isDuplicationEnable()
            && this.reputFromOffset >= DefaultMessageStore.this.getConfirmOffset()) {
            break;
        }

        // 获取从指定位置开始的commitlog文件
        SelectMappedBufferResult result = DefaultMessageStore.this.commitLog.getData(reputFromOffset);
        if (result != null) {
            try {
                // 这里的startOffset等于最新的commitlog文件的fileFromOffset + (reputFromOffset % mappedFileSize)
                this.reputFromOffset = result.getStartOffset();

                // size等于commitlog文件的wrotePosition - (reputFromOffset % mappedFileSize)，所以这里相当于遍历commitlog
                // 文件中已经写入pageCache但是还没有被这里的deRepot方法处理的数据
                for (int readSize = 0; readSize < result.getSize() && doNext; ) {
                    /*
                    result.getByteBuffer()返回(reputFromOffset % mappedFileSize)到size部分的数据
                    正如checkMessageAndReturnSize方法的返回值所示，这里从这部分数据中读出一条消息相关的数据
                    return new DispatchRequest(
                        topic,
                        queueId,
                        physicOffset,
                        totalSize,
                        tagsCode,
                        storeTimestamp,
                        queueOffset,
                        keys,
                        uniqKey,
                        sysFlag,
                        preparedTransactionOffset,
                        propertiesMap
                    );
                    */
                    DispatchRequest dispatchRequest =
                        DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false);
                    int size = dispatchRequest.getBufferSize() == -1 ? dispatchRequest.getMsgSize() : dispatchRequest.getBufferSize();

                    if (dispatchRequest.isSuccess()) {
                        if (size > 0) {
                            // 遍历CommitLogDispatcher对象处理当前的消息，CommitLogDispatcher默认有两个，CommitLogDispatcherBuildConsumeQueue
                            // 和CommitLogDispatcherBuildIndex
                            DefaultMessageStore.this.doDispatch(dispatchRequest);

                            // 如果是master broker并且开启了长轮询
                            if (BrokerRole.SLAVE != DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole()
                                && DefaultMessageStore.this.brokerConfig.isLongPollingEnable()) {
                                // 通知messageArrivingListener有消息到达了，默认messageArrivingListener会执行
                                // PullRequestHoldService类的notifyMessageArriving方法尝试判断是否有被挂起的消费者拉
                                // 取消息请求，如果有则判断到达的消息是否满足拉取请求，满足则取消挂起使得拉取消息请求返回
                                DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(),
                                    dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1,
                                    dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(),
                                    dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap());
                            }

                            // 更新处理完成的位置
                            this.reputFromOffset += size;
                            readSize += size;
                            // 计算统计数据
                            if (DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() == BrokerRole.SLAVE) {
                                DefaultMessageStore.this.storeStatsService
                                    .getSinglePutMessageTopicTimesTotal(dispatchRequest.getTopic()).incrementAndGet();
                                DefaultMessageStore.this.storeStatsService
                                    .getSinglePutMessageTopicSizeTotal(dispatchRequest.getTopic())
                                    .addAndGet(dispatchRequest.getMsgSize());
                            }
                        } else if (size == 0) {
                            this.reputFromOffset = DefaultMessageStore.this.commitLog.rollNextFile(this.reputFromOffset);
                            readSize = result.getSize();
                        }
                    } else if (!dispatchRequest.isSuccess()) {

                        if (size > 0) {
                            log.error("[BUG]read total count not equals msg total size. reputFromOffset={}", reputFromOffset);
                            this.reputFromOffset += size;
                        } else {
                            doNext = false;
                            // If user open the dledger pattern or the broker is master node,
                            // it will not ignore the exception and fix the reputFromOffset variable
                            if (DefaultMessageStore.this.getMessageStoreConfig().isEnableDLegerCommitLog() ||
                                DefaultMessageStore.this.brokerConfig.getBrokerId() == MixAll.MASTER_ID) {
                                log.error("[BUG]dispatch message to consume queue error, COMMITLOG OFFSET: {}",
                                    this.reputFromOffset);
                                this.reputFromOffset += result.getSize() - readSize;
                            }
                        }
                    }
                }
            } finally {
                result.release();
            }
        } else {
            doNext = false;
        }
    }
}
```

`doReput()`方法通过`reputFromOffset`变量保存已经处理过的位置，遍历commitlog文件中的消息，将每条消息封装为`DispatchRequest`对象并交由`DefaultMessageStore`类的`doDispatch()`方法处理，下面是`doDispatch()`方法的实现：
```java
public void doDispatch(DispatchRequest req) {
    for (CommitLogDispatcher dispatcher : this.dispatcherList) {
        dispatcher.dispatch(req);
    }
}
```

`dispatcherList`属性在`DefaultMessageStore`类的构造函数被初始化，代码如下：
```java
this.dispatcherList = new LinkedList<>();
this.dispatcherList.addLast(new CommitLogDispatcherBuildConsumeQueue());
this.dispatcherList.addLast(new CommitLogDispatcherBuildIndex());
```

`CommitLogDispatcherBuildConsumeQueue`类和`CommitLogDispatcherBuildIndex`类分别用于构建consumequeue文件和index文件，即一个用于生成broker中队列的数据，一个用于生成消息的索引。这里先分析`CommitLogDispatcherBuildConsumeQueue`的实现，该类代码如下：
```java
class CommitLogDispatcherBuildConsumeQueue implements CommitLogDispatcher {

    @Override
    public void dispatch(DispatchRequest request) {
        final int tranType = MessageSysFlag.getTransactionValue(request.getSysFlag());
        switch (tranType) {
            case MessageSysFlag.TRANSACTION_NOT_TYPE: // 如果是普通的消息
            case MessageSysFlag.TRANSACTION_COMMIT_TYPE: // 如果是事务提交的消息
                DefaultMessageStore.this.putMessagePositionInfo(request);
                break;
            case MessageSysFlag.TRANSACTION_PREPARED_TYPE: // 如果是事务的半消息
            case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE: // 如果是事务的回滚消息
                break;
        }
    }
}
```

对于事务消息相关的处理可以看笔记[如何实现事务消息](如何实现事务消息.md)，对于普通消息，由`DefaultMessageStore`类的`putMessagePositionInfo()`方法处理，代码如下：
```java
public void putMessagePositionInfo(DispatchRequest dispatchRequest) {
    ConsumeQueue cq = this.findConsumeQueue(dispatchRequest.getTopic(), dispatchRequest.getQueueId());
    cq.putMessagePositionInfoWrapper(dispatchRequest);
}

public ConsumeQueue findConsumeQueue(String topic, int queueId) {
    ConcurrentMap<Integer, ConsumeQueue> map = consumeQueueTable.get(topic);
    if (null == map) {
        ConcurrentMap<Integer, ConsumeQueue> newMap = new ConcurrentHashMap<Integer, ConsumeQueue>(128);
        ConcurrentMap<Integer, ConsumeQueue> oldMap = consumeQueueTable.putIfAbsent(topic, newMap);
        if (oldMap != null) {
            map = oldMap;
        } else {
            map = newMap;
        }
    }

    ConsumeQueue logic = map.get(queueId);
    if (null == logic) {
        ConsumeQueue newLogic = new ConsumeQueue(
            topic,
            queueId,
            StorePathConfigHelper.getStorePathConsumeQueue(this.messageStoreConfig.getStorePathRootDir()),
            this.getMessageStoreConfig().getMappedFileSizeConsumeQueue(),
            this);
        ConsumeQueue oldLogic = map.putIfAbsent(queueId, newLogic);
        if (oldLogic != null) {
            logic = oldLogic;
        } else {
            logic = newLogic;
        }
    }

    return logic;
}
```

`putMessagePositionInfo()`方法调用`findConsumeQueue()`方法获取`ConsumeQueue`对象，获取过程很简单，从`consumeQueueTable`属性获取topic的queueId对应的`ConsumeQueue`对象，没有则创建一个。之后`putMessagePositionInfo()`方法调用`ConsumeQueue`类的`putMessagePositionInfoWrapper()`方法处理`DispatchRequest`对象，该方法代码如下：
```java
// DispatchRequest对象包含了一个被保存到CommitLog文件的消息的全部信息
public void putMessagePositionInfoWrapper(DispatchRequest request) {
    // 重试写入的次数
    final int maxRetries = 30;
    // 根据RunningFlags的各种标志位判断当前是否能够执行consumequeue文件的写入操作
    boolean canWrite = this.defaultMessageStore.getRunningFlags().isCQWriteable();
    for (int i = 0; i < maxRetries && canWrite; i++) {
        long tagsCode = request.getTagsCode();
        // 如果开启的ConsumeQueueExt，则会额外写一些信息到consumequeue_ext文件
        if (isExtWriteEnable()) {
            ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit();
            cqExtUnit.setFilterBitMap(request.getBitMap()); // 当前消息的topic对应的bitmap数据
            cqExtUnit.setMsgStoreTime(request.getStoreTimestamp()); // 消息被保存到broker的时间（CommitLog对象的putMessage方法设置的）
            cqExtUnit.setTagsCode(request.getTagsCode()); // 消息标签的hash值，如果消息被保存在定时消息的topic，则tagsCode属性为消息应该被消费的时间戳

            long extAddr = this.consumeQueueExt.put(cqExtUnit);
            if (isExtAddr(extAddr)) {
                tagsCode = extAddr;
            } else {
                log.warn("Save consume queue extend fail, So just save tagsCode! {}, topic:{}, queueId:{}, offset:{}", cqExtUnit,
                    topic, queueId, request.getCommitLogOffset());
            }
        }
        // 保存消息的位移、消息大小、tagsCode到consumequeue文件
        boolean result = this.putMessagePositionInfo(request.getCommitLogOffset(),
            request.getMsgSize(), tagsCode, request.getConsumeQueueOffset());
        if (result) {
            if (this.defaultMessageStore.getMessageStoreConfig().getBrokerRole() == BrokerRole.SLAVE ||
                this.defaultMessageStore.getMessageStoreConfig().isEnableDLegerCommitLog()) {
                this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(request.getStoreTimestamp());
            }
            // 更新checkpoint文件的logicsMsgTimestamp记录
            this.defaultMessageStore.getStoreCheckpoint().setLogicsMsgTimestamp(request.getStoreTimestamp());
            return;
        } else {
            // 写入失败记录日志
            // XXX: warn and notify me
            log.warn("[BUG]put commit log position info to " + topic + ":" + queueId + " " + request.getCommitLogOffset()
                + " failed, retry " + i + " times");

            try {
                // sleep 1s后重试
                Thread.sleep(1000);
            } catch (InterruptedException e) {
                log.warn("", e);
            }
        }
    }

    // XXX: warn and notify me
    log.error("[BUG]consume queue can not write, {} {}", this.topic, this.queueId);
    this.defaultMessageStore.getRunningFlags().makeLogicsQueueError();
}
```

`putMessagePositionInfoWrapper()`方法最终会调用`ConsumeQueue`类的`putMessagePositionInfo()`方法：
```java
private boolean putMessagePositionInfo(final long offset, final int size, final long tagsCode,
    final long cqOffset) {

    // 如果当前消息的位移小于已经保存的消息的最大位移，则认为消息被保存过了，直接返回true
    if (offset + size <= this.maxPhysicOffset) {
        log.warn("Maybe try to build consume queue repeatedly maxPhysicOffset={} phyOffset={}", maxPhysicOffset, offset);
        return true;
    }

    this.byteBufferIndex.flip();
    // consumequeue中一条记录固定20字节
    this.byteBufferIndex.limit(CQ_STORE_UNIT_SIZE);
    // 保存消息位移
    this.byteBufferIndex.putLong(offset);
    // 保存消息大小
    this.byteBufferIndex.putInt(size);
    // 保存消息标签的hash
    this.byteBufferIndex.putLong(tagsCode);

    // cqOffset属性为消息被保存到commitlog文件时，其对应的队列已经保存的消息数量，这里将cqOffset乘以consumequeue文件内每条记录
    // 的大小，就能得到该消息在consumequeue中的位移，同时也保证了consumequeue内记录的顺序和消息被保存到commitlog文件的顺序一致
    final long expectLogicOffset = cqOffset * CQ_STORE_UNIT_SIZE;

    // 获取最小的consumequeue文件
    MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(expectLogicOffset);
    if (mappedFile != null) {

        // 如果当前consumequeue文件是当前队列的文件夹下第一个被创建的文件，并且当前消息的位置大于0，则在之前的位置填上空白
        // 出现这种情况可能是当前队列对应的consumequeue文件都被删除了
        if (mappedFile.isFirstCreateInQueue() && cqOffset != 0 && mappedFile.getWrotePosition() == 0) {
            this.minLogicOffset = expectLogicOffset;
            this.mappedFileQueue.setFlushedWhere(expectLogicOffset);
            this.mappedFileQueue.setCommittedWhere(expectLogicOffset);
            // 将expectLogicOffset之前的位置填上空白
            this.fillPreBlank(mappedFile, expectLogicOffset);
            log.info("fill pre blank space " + mappedFile.getFileName() + " " + expectLogicOffset + " "
                + mappedFile.getWrotePosition());
        }

        if (cqOffset != 0) {
            // 获取当前已经保存的字节数
            long currentLogicOffset = mappedFile.getWrotePosition() + mappedFile.getFileFromOffset();

            // expectLogicOffset < currentLogicOffset说明是重复写入，直接返回true
            if (expectLogicOffset < currentLogicOffset) {
                log.warn("Build  consume queue repeatedly, expectLogicOffset: {} currentLogicOffset: {} Topic: {} QID: {} Diff: {}",
                    expectLogicOffset, currentLogicOffset, this.topic, this.queueId, expectLogicOffset - currentLogicOffset);
                return true;
            }

            // 因为expectLogicOffset = cqOffset * CQ_STORE_UNIT_SIZE，而cqOffset是从0开始计数的，所以理论上因为expectLogicOffset
            // 应该等于currentLogicOffset
            if (expectLogicOffset != currentLogicOffset) {
                LOG_ERROR.warn(
                    "[BUG]logic queue order maybe wrong, expectLogicOffset: {} currentLogicOffset: {} Topic: {} QID: {} Diff: {}",
                    expectLogicOffset,
                    currentLogicOffset,
                    this.topic,
                    this.queueId,
                    expectLogicOffset - currentLogicOffset
                );
            }
        }
        // 更新最大位移值
        this.maxPhysicOffset = offset + size;
        // 保存消息的consumequeue记录
        return mappedFile.appendMessage(this.byteBufferIndex.array());
    }
    return false;
}
```

`putMessagePositionInfo()`方法就是简单的将从`DispatchRequest`对象获取到的消息的位移、大小、标签的hashCode信息保存到consumequeue文件，由于需要保存的信息是固定的，所以一条消息在consumequeue文件中的记录大小也就是固定的20字节。

以上是`CommitLogDispatcherBuildConsumeQueue`类为commitlog文件中的消息添加consumequeue记录的过程，下面在分析`CommitLogDispatcherBuildIndex`类构建消息索引的过程。

以上就是消息存储的过程。

