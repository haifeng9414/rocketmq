根据笔记[如何处理发送消息的请求](如何处理发送消息的请求.md)可知，生产者发送的消息在broker端由`MessageStore`接口的`putMessage()`方法完成存储，`MessageStore`接口的默认实现类是`DefaultMessageStore`类。`MessageStore`接口定义了消息存储应该提供的方法：
```java
public interface MessageStore {
    boolean load();

    void start() throws Exception;

    void shutdown();

    void destroy();

    PutMessageResult putMessage(final MessageExtBrokerInner msg);

    PutMessageResult putMessages(final MessageExtBatch messageExtBatch);

    GetMessageResult getMessage(final String group, final String topic, final int queueId,
        final long offset, final int maxMsgNums, final MessageFilter messageFilter);

    long getMaxOffsetInQueue(final String topic, final int queueId);

    long getMinOffsetInQueue(final String topic, final int queueId);

    long getCommitLogOffsetInQueue(final String topic, final int queueId, final long consumeQueueOffset);

    long getOffsetInQueueByTime(final String topic, final int queueId, final long timestamp);

    MessageExt lookMessageByOffset(final long commitLogOffset);

    SelectMappedBufferResult selectOneMessageByOffset(final long commitLogOffset);

    SelectMappedBufferResult selectOneMessageByOffset(final long commitLogOffset, final int msgSize);

    String getRunningDataInfo();

    HashMap<String, String> getRuntimeInfo();

    long getMaxPhyOffset();

    long getMinPhyOffset();

    long getEarliestMessageTime(final String topic, final int queueId);

    long getEarliestMessageTime();

     
    long getMessageStoreTimeStamp(final String topic, final int queueId, final long consumeQueueOffset);

    long getMessageTotalInQueue(final String topic, final int queueId);

    SelectMappedBufferResult getCommitLogData(final long offset);

    boolean appendToCommitLog(final long startOffset, final byte[] data);

    void executeDeleteFilesManually();

    QueryMessageResult queryMessage(final String topic, final String key, final int maxNum, final long begin,
        final long end);

    void updateHaMasterAddress(final String newAddr);

    long slaveFallBehindMuch();

    long now();

    int cleanUnusedTopic(final Set<String> topics);

    void cleanExpiredConsumerQueue();

    boolean checkInDiskByConsumeOffset(final String topic, final int queueId, long consumeOffset);

    long dispatchBehindBytes();

    long flush();

    boolean resetWriteOffset(long phyOffset);

    long getConfirmOffset();

    void setConfirmOffset(long phyOffset);

    boolean isOSPageCacheBusy();

    long lockTimeMills();

    boolean isTransientStorePoolDeficient();

    LinkedList<CommitLogDispatcher> getDispatcherList();

    ConsumeQueue getConsumeQueue(String topic, int queueId);

    BrokerStatsManager getBrokerStatsManager();

    void handleScheduleMessageService(BrokerRole brokerRole);
}
```

上面的方法的作用在下面碰到的时候再逐个分析，这里直接开始分析消息存储的过程。rocketmq中`MessageStore`接口的实现类有两个，分别是`AbstractPluginMessageStore`抽象类和`DefaultMessageStore`类。`AbstractPluginMessageStore`抽象类只是为了支持自定义的`MessageStore`实现类，在broker启动时，会初始化`MessageStore`接口的实现类，代码在`BrokerController`类的`initialize()`方法：
```java
public boolean initialize() throws CloneNotSupportedException {
    // 略

    if (result) {
        try {
            this.messageStore =
                new DefaultMessageStore(this.messageStoreConfig, this.brokerStatsManager, this.messageArrivingListener,
                    this.brokerConfig);
            
            // 略

            //load plugin
            MessageStorePluginContext context = new MessageStorePluginContext(messageStoreConfig, brokerStatsManager, messageArrivingListener, brokerConfig);

            this.messageStore = MessageStoreFactory.build(context, this.messageStore);
            this.messageStore.getDispatcherList().addFirst(new CommitLogDispatcherCalcBitMap(this.brokerConfig, this.consumerFilterManager));
        } catch (IOException e) {
            // 略
        }
    }

    // 略
}
```

可以看到，`BrokerController`首先创建了`DefaultMessageStore`对象，之后再用`MessageStoreFactory`的`build()`方法创建一个`MessageStore`接口的实现，`build()`方法代码如下：
```java
public final static MessageStore build(MessageStorePluginContext context, MessageStore messageStore)
    throws IOException {
    String plugin = context.getBrokerConfig().getMessageStorePlugIn();
    if (plugin != null && plugin.trim().length() != 0) {
        String[] pluginClasses = plugin.split(",");
        for (int i = pluginClasses.length - 1; i >= 0; --i) {
            String pluginClass = pluginClasses[i];
            try {
                @SuppressWarnings("unchecked")
                Class<AbstractPluginMessageStore> clazz = (Class<AbstractPluginMessageStore>) Class.forName(pluginClass);
                Constructor<AbstractPluginMessageStore> construct = clazz.getConstructor(MessageStorePluginContext.class, MessageStore.class);
                messageStore = construct.newInstance(context, messageStore);
            } catch (Throwable e) {
                throw new RuntimeException(String.format(
                    "Initialize plugin's class %s not found!", pluginClass), e);
            }
        }
    }
    return messageStore;
}
```

上面的代码很简单，就是反射创建插件的实现类，并且插件的实现类要求继承自`AbstractPluginMessageStore`，下面是`AbstractPluginMessageStore`抽象类的代码：
```java
public abstract class AbstractPluginMessageStore implements MessageStore {
    protected MessageStore next = null;
    protected MessageStorePluginContext context;

    public AbstractPluginMessageStore(MessageStorePluginContext context, MessageStore next) {
        this.next = next;
        this.context = context;
    }

    @Override
    public long getEarliestMessageTime() {
        return next.getEarliestMessageTime();
    }

    @Override
    public long lockTimeMills() {
        return next.lockTimeMills();
    }

    @Override
    public boolean isOSPageCacheBusy() {
        return next.isOSPageCacheBusy();
    }

    @Override
    public boolean isTransientStorePoolDeficient() {
        return next.isTransientStorePoolDeficient();
    }

    @Override
    public boolean load() {
        return next.load();
    }

    @Override
    public void start() throws Exception {
        next.start();
    }

    @Override
    public void shutdown() {
        next.shutdown();
    }

    @Override
    public void destroy() {
        next.destroy();
    }

    @Override
    public PutMessageResult putMessage(MessageExtBrokerInner msg) {
        return next.putMessage(msg);
    }

    @Override
    public GetMessageResult getMessage(String group, String topic, int queueId, long offset,
        int maxMsgNums, final MessageFilter messageFilter) {
        return next.getMessage(group, topic, queueId, offset, maxMsgNums, messageFilter);
    }

    @Override
    public long getMaxOffsetInQueue(String topic, int queueId) {
        return next.getMaxOffsetInQueue(topic, queueId);
    }

    @Override
    public long getMinOffsetInQueue(String topic, int queueId) {
        return next.getMinOffsetInQueue(topic, queueId);
    }

    @Override
    public long getCommitLogOffsetInQueue(String topic, int queueId, long consumeQueueOffset) {
        return next.getCommitLogOffsetInQueue(topic, queueId, consumeQueueOffset);
    }

    @Override
    public long getOffsetInQueueByTime(String topic, int queueId, long timestamp) {
        return next.getOffsetInQueueByTime(topic, queueId, timestamp);
    }

    @Override
    public MessageExt lookMessageByOffset(long commitLogOffset) {
        return next.lookMessageByOffset(commitLogOffset);
    }

    @Override
    public SelectMappedBufferResult selectOneMessageByOffset(long commitLogOffset) {
        return next.selectOneMessageByOffset(commitLogOffset);
    }

    @Override
    public SelectMappedBufferResult selectOneMessageByOffset(long commitLogOffset, int msgSize) {
        return next.selectOneMessageByOffset(commitLogOffset, msgSize);
    }

    @Override
    public String getRunningDataInfo() {
        return next.getRunningDataInfo();
    }

    @Override
    public HashMap<String, String> getRuntimeInfo() {
        return next.getRuntimeInfo();
    }

    @Override
    public long getMaxPhyOffset() {
        return next.getMaxPhyOffset();
    }

    @Override
    public long getMinPhyOffset() {
        return next.getMinPhyOffset();
    }

    @Override
    public long getEarliestMessageTime(String topic, int queueId) {
        return next.getEarliestMessageTime(topic, queueId);
    }

    @Override
    public long getMessageStoreTimeStamp(String topic, int queueId, long consumeQueueOffset) {
        return next.getMessageStoreTimeStamp(topic, queueId, consumeQueueOffset);
    }

    @Override
    public long getMessageTotalInQueue(String topic, int queueId) {
        return next.getMessageTotalInQueue(topic, queueId);
    }

    @Override
    public SelectMappedBufferResult getCommitLogData(long offset) {
        return next.getCommitLogData(offset);
    }

    @Override
    public boolean appendToCommitLog(long startOffset, byte[] data) {
        return next.appendToCommitLog(startOffset, data);
    }

    @Override
    public void executeDeleteFilesManually() {
        next.executeDeleteFilesManually();
    }

    @Override
    public QueryMessageResult queryMessage(String topic, String key, int maxNum, long begin,
        long end) {
        return next.queryMessage(topic, key, maxNum, begin, end);
    }

    @Override
    public void updateHaMasterAddress(String newAddr) {
        next.updateHaMasterAddress(newAddr);
    }

    @Override
    public long slaveFallBehindMuch() {
        return next.slaveFallBehindMuch();
    }

    @Override
    public long now() {
        return next.now();
    }

    @Override
    public int cleanUnusedTopic(Set<String> topics) {
        return next.cleanUnusedTopic(topics);
    }

    @Override
    public void cleanExpiredConsumerQueue() {
        next.cleanExpiredConsumerQueue();
    }

    @Override
    public boolean checkInDiskByConsumeOffset(String topic, int queueId, long consumeOffset) {
        return next.checkInDiskByConsumeOffset(topic, queueId, consumeOffset);
    }

    @Override
    public long dispatchBehindBytes() {
        return next.dispatchBehindBytes();
    }

    @Override
    public long flush() {
        return next.flush();
    }

    @Override
    public boolean resetWriteOffset(long phyOffset) {
        return next.resetWriteOffset(phyOffset);
    }

    @Override
    public long getConfirmOffset() {
        return next.getConfirmOffset();
    }

    @Override
    public void setConfirmOffset(long phyOffset) {
        next.setConfirmOffset(phyOffset);
    }

    @Override
    public LinkedList<CommitLogDispatcher> getDispatcherList() {
        return next.getDispatcherList();
    }

    @Override
    public ConsumeQueue getConsumeQueue(String topic, int queueId) {
        return next.getConsumeQueue(topic, queueId);
    }

    @Override
    public BrokerStatsManager getBrokerStatsManager() {
        return next.getBrokerStatsManager();
    };
}
```

可以说`AbstractPluginMessageStore`类什么也没做，只是组合了`MessageStorePluginContext`对象和一个`MessageStore`接口的实现类，自定义插件可以通过继承`AbstractPluginMessageStore`类并重写若干方法实现修改`MessageStore`接口的实现类的相关逻辑的效果，而上面的`MessageStore`接口的实现类就是`DefaultMessageStore`类，rocketmq中消息存储的相关功能都是该类实现的，下面着重分析该类的实现。

`BrokerController`类首先使用到`DefaultMessageStore`的地方是其`start()`方法：
```java
public void start() throws Exception {
    if (this.messageStore != null) {
        this.messageStore.start();
    }

    // 略
}
```

所以这里先看`DefaultMessageStore`的`start()`方法：
```java
public void start() throws Exception {

    // 获取store/lock文件的独占锁以防止start方法被重复调用
    lock = lockFile.getChannel().tryLock(0, 1, false);
    if (lock == null || lock.isShared() || !lock.isValid()) {
        throw new RuntimeException("Lock failed,MQ already started");
    }

    lockFile.getChannel().write(ByteBuffer.wrap("lock".getBytes()));
    // 强制刷盘
    lockFile.getChannel().force(true);
    {
        /**
         * 1. Make sure the fast-forward messages to be truncated during the recovering according to the max physical offset of the commitlog;
         * 2. DLedger committedPos may be missing, so the maxPhysicalPosInLogicQueue maybe bigger that maxOffset returned by DLedgerCommitLog, just let it go;
         * 3. Calculate the reput offset according to the consume queue;
         * 4. Make sure the fall-behind messages to be dispatched before starting the commitlog, especially when the broker role are automatically changed.
         */
        long maxPhysicalPosInLogicQueue = commitLog.getMinOffset();
        // 遍历ConsumeQueue，获取commitlog文件里所有被放置到consumeQueue的消息的最大物理地址
        for (ConcurrentMap<Integer, ConsumeQueue> maps : this.consumeQueueTable.values()) {
            for (ConsumeQueue logic : maps.values()) {
                // getMaxPhysicOffset方法返回consumeQueue中最新的消息的commitlogOffset + 其在commitlog文件中占用的字节数
                if (logic.getMaxPhysicOffset() > maxPhysicalPosInLogicQueue) {
                    maxPhysicalPosInLogicQueue = logic.getMaxPhysicOffset();
                }
            }
        }
        if (maxPhysicalPosInLogicQueue < 0) {
            maxPhysicalPosInLogicQueue = 0;
        }
        if (maxPhysicalPosInLogicQueue < this.commitLog.getMinOffset()) {
            maxPhysicalPosInLogicQueue = this.commitLog.getMinOffset();
            /**
             * This happens in following conditions:
             * 1. If someone removes all the consumequeue files or the disk get damaged.
             * 2. Launch a new broker, and copy the commitlog from other brokers.
             *
             * All the conditions has the same in common that the maxPhysicalPosInLogicQueue should be 0.
             * If the maxPhysicalPosInLogicQueue is gt 0, there maybe something wrong.
             */
            log.warn("[TooSmallCqOffset] maxPhysicalPosInLogicQueue={} clMinOffset={}", maxPhysicalPosInLogicQueue, this.commitLog.getMinOffset());
        }
        log.info("[SetReputOffset] maxPhysicalPosInLogicQueue={} clMinOffset={} clMaxOffset={} clConfirmedOffset={}",
            maxPhysicalPosInLogicQueue, this.commitLog.getMinOffset(), this.commitLog.getMaxOffset(), this.commitLog.getConfirmOffset());
        // reputMessageService对象会不断的扫描所有的commitlog文件，不断的取出消息并交由CommitLogDispatcher对象处理，对于
        // 处理过的消息不会重复处理。为了实现不重复处理，需要保存已经处理过的消息的偏移量，下面的reputFromOffset变量的值就是这个
        // 偏移量。默认CommitLogDispatcher对象包括CommitLogDispatcherBuildConsumeQueue类，该类的作用是根据commitlog中的
        // 消息创建consumeQueue，所以可以看到上面在计算maxPhysicalPosInLogicQueue时会遍历所有的ConsumeQueue，如果消息已经
        // 在consumeQueue存在了就不需要再通过reputMessageService对象进行处理了。
        this.reputMessageService.setReputFromOffset(maxPhysicalPosInLogicQueue);
        // reputMessageService对象本质上是个线程，这里启动线程
        this.reputMessageService.start();

        /**
         *  1. Finish dispatching the messages fall behind, then to start other services.
         *  2. DLedger committedPos may be missing, so here just require dispatchBehindBytes <= 0
         */
        while (true) {
            // dispatchBehindBytes方法返回所有的commitlog中有多少字节的数据还没被reputMessageService对象处理
            if (dispatchBehindBytes() <= 0) { // 小于等于0说明全部都处理完了，此时break即可
                break;
            }
            Thread.sleep(1000); // 否则循环的sleep直到处理完
            log.info("Try to finish doing reput the messages fall behind during the starting, reputOffset={} maxOffset={} behind={}", this.reputMessageService.getReputFromOffset(), this.getMaxPhyOffset(), this.dispatchBehindBytes());
        }
        // 根据consumeQueueTable的值计算commitlog的topicQueueTable属性值，也就是计算所有的topic下的queue各自保存了多少消息的
        // consume信息
        this.recoverTopicQueueTable();
    }

    if (!messageStoreConfig.isEnableDLegerCommitLog()) {
        this.haService.start();
        this.handleScheduleMessageService(messageStoreConfig.getBrokerRole());
    }

    this.flushConsumeQueueService.start();
    this.commitLog.start();
    this.storeStatsService.start();

    // 创建store/abort文件，该文件的作用体现在load方法中
    this.createTempFile();
    // 开启若干定时任务，最重要的时定时执行cleanCommitLogService和cleanConsumeQueueService
    this.addScheduleTask();
    this.shutdown = false;
}
```

`start()`方法最重要的是启动了若干组件，开启了若干定时任务，这些组件和定时任务的作用在下面分析消息存储的过程再分析。当`start()`方法执行之后，`DefaultMessageStore`对象就可以开始保存消息了。

保存消息的方法是`DefaultMessageStore`对象的`putMessage()`方法：
```java
public PutMessageResult putMessage(MessageExtBrokerInner msg) {
    if (this.shutdown) {
        log.warn("message store has shutdown, so putMessage is forbidden");
        return new PutMessageResult(PutMessageStatus.SERVICE_NOT_AVAILABLE, null);
    }

    // slave节点的put操作直接报错，下面都是处理各种异常的情况
    if (BrokerRole.SLAVE == this.messageStoreConfig.getBrokerRole()) {
        // 记录收到的不合法写入消息请求的次数
        long value = this.printTimes.getAndIncrement();
        // 每50000次记一次日志，这样能够减少日志数量
        if ((value % 50000) == 0) {
            log.warn("message store is slave mode, so putMessage is forbidden ");
        }

        return new PutMessageResult(PutMessageStatus.SERVICE_NOT_AVAILABLE, null);
    }

    if (!this.runningFlags.isWriteable()) {
        long value = this.printTimes.getAndIncrement();
        if ((value % 50000) == 0) {
            log.warn("message store is not writeable, so putMessage is forbidden " + this.runningFlags.getFlagBits());
        }

        return new PutMessageResult(PutMessageStatus.SERVICE_NOT_AVAILABLE, null);
    } else {
        this.printTimes.set(0);
    }

    // topic太长，报错
    if (msg.getTopic().length() > Byte.MAX_VALUE) {
        log.warn("putMessage message topic length too long " + msg.getTopic().length());
        return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, null);
    }

    // 属性太长，报错
    if (msg.getPropertiesString() != null && msg.getPropertiesString().length() > Short.MAX_VALUE) {
        log.warn("putMessage message properties length too long " + msg.getPropertiesString().length());
        return new PutMessageResult(PutMessageStatus.PROPERTIES_SIZE_EXCEEDED, null);
    }

    // isOSPageCacheBusy方法默认在commitlog文件被lock超过1s时返回true
    if (this.isOSPageCacheBusy()) {
        return new PutMessageResult(PutMessageStatus.OS_PAGECACHE_BUSY, null);
    }

    // 返回当前时间
    long beginTime = this.getSystemClock().now();
    // 保存消息
    PutMessageResult result = this.commitLog.putMessage(msg);

    // 获取保存消息耗时
    long elapsedTime = this.getSystemClock().now() - beginTime;
    if (elapsedTime > 500) {
        log.warn("putMessage not in lock elapsed time(ms)={}, bodyLength={}", elapsedTime, msg.getBody().length);
    }
    // 保存耗时信息，用于统计
    this.storeStatsService.setPutMessageEntireTimeMax(elapsedTime);

    // 如果失败则增加失败次数
    if (null == result || !result.isOk()) {
        this.storeStatsService.getPutMessageFailedTimes().incrementAndGet();
    }

    return result;
}
```

上面的代码逻辑并不多，只是做了一些必要的参数校验，判断当前broker是否繁忙，如果验证通过，就执行`CommitLog`对象的`putMessage()`方法保存消息。这里值得注意的是判断broker是否繁忙的逻辑，对应的代码在`isOSPageCacheBusy()`方法：
```java
public boolean isOSPageCacheBusy() {
    // 如果commitlog文件正在被lock，则beginTimeInLock等于开始lock的时间，否则等于0
    long begin = this.getCommitLog().getBeginTimeInLock();
    long diff = this.systemClock.now() - begin;

    // 当commitlog文件未被lock时begin等于0，此时diff肯定大于10000000，直接返回false
    // this.messageStoreConfig.getOsPageCacheBusyTimeOutMills()默认返回1s，这里在diff大于1s的情况下返回busy
    return diff < 10000000
        && diff > this.messageStoreConfig.getOsPageCacheBusyTimeOutMills();
}
```

下面再看`CommitLog`对象的`putMessage()`方法是如何实现的：
```java
public PutMessageResult putMessage(final MessageExtBrokerInner msg) {
    // Set the storage time
    msg.setStoreTimestamp(System.currentTimeMillis());
    // Set the message body BODY CRC (consider the most appropriate setting
    // on the client)
    msg.setBodyCRC(UtilAll.crc32(msg.getBody()));
    // Back to Results
    AppendMessageResult result = null;

    StoreStatsService storeStatsService = this.defaultMessageStore.getStoreStatsService();

    String topic = msg.getTopic();
    int queueId = msg.getQueueId();

    final int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag());
    if (tranType == MessageSysFlag.TRANSACTION_NOT_TYPE
        || tranType == MessageSysFlag.TRANSACTION_COMMIT_TYPE) {
        // Delay Delivery
        // 如果是延迟消息
        if (msg.getDelayTimeLevel() > 0) {
            if (msg.getDelayTimeLevel() > this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel()) {
                msg.setDelayTimeLevel(this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel());
            }

            topic = ScheduleMessageService.SCHEDULE_TOPIC;
            queueId = ScheduleMessageService.delayLevel2QueueId(msg.getDelayTimeLevel());

            // Backup real topic, queueId
            MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_TOPIC, msg.getTopic());
            MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msg.getQueueId()));
            msg.setPropertiesString(MessageDecoder.messageProperties2String(msg.getProperties()));

            msg.setTopic(topic);
            msg.setQueueId(queueId);
        }
    }

    // 获取客户端地址
    InetSocketAddress bornSocketAddress = (InetSocketAddress) msg.getBornHost();
    if (bornSocketAddress.getAddress() instanceof Inet6Address) {
        msg.setBornHostV6Flag();
    }

    // storeHost默认就是当前broker地址
    InetSocketAddress storeSocketAddress = (InetSocketAddress) msg.getStoreHost();
    if (storeSocketAddress.getAddress() instanceof Inet6Address) {
        msg.setStoreHostAddressV6Flag();
    }

    long eclipsedTimeInLock = 0;

    MappedFile unlockMappedFile = null;
    // MappedFile实际上就是某个commitlog或consumeQueue文件，这里获取最新的commitlog文件
    MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile();

    // putMessageLock可能是ReentrantLock也可能是自选锁，根据配置决定，默认使用自旋锁
    putMessageLock.lock(); //spin or ReentrantLock ,depending on store config
    try {
        // 获取当前时间
        long beginLockTimestamp = this.defaultMessageStore.getSystemClock().now();
        // 记录开始lock的时间
        this.beginTimeInLock = beginLockTimestamp;

        // Here settings are stored timestamp, in order to ensure an orderly
        // global
        // 设置消息保存时间，对于某个客户端，其同步发送的消息是有响应的。如果客户端的某个线程发送消息时将某类消息（如根据业务key做
        // hash选择队列）发往同一个broker的同一个队列，那么客户端发送这类消息的顺序和broker收到消息的顺序肯定是一样的，这样在这里
        // 为消息保存系统当前时间，就能根据该时间得知客户端发送的那类消息的顺序
        msg.setStoreTimestamp(beginLockTimestamp);

        // 判断这个最新的commitlog文件是否为空或是否已经写满
        if (null == mappedFile || mappedFile.isFull()) {
            // 新建一个MappedFile文件，即新建一个commitlog文件
            mappedFile = this.mappedFileQueue.getLastMappedFile(0); // Mark: NewFile may be cause noise
        }
        // 创建失败则报错
        if (null == mappedFile) {
            log.error("create mapped file1 error, topic: " + msg.getTopic() + " clientAddr: " + msg.getBornHostString());
            beginTimeInLock = 0;
            return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, null);
        }

        // 将消息附加到commitlog文件
        result = mappedFile.appendMessage(msg, this.appendMessageCallback);
        switch (result.getStatus()) {
            case PUT_OK: // 保存成功直接返回
                break;
            case END_OF_FILE: // 如果最新的commitlog文件的剩余容量不够放置当前消息
                unlockMappedFile = mappedFile;
                // Create a new file, re-write the message
                // 新建一个commitlog文件
                mappedFile = this.mappedFileQueue.getLastMappedFile(0);
                // 新建失败则返回err
                if (null == mappedFile) {
                    // XXX: warn and notify me
                    log.error("create mapped file2 error, topic: " + msg.getTopic() + " clientAddr: " + msg.getBornHostString());
                    beginTimeInLock = 0;
                    return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, result);
                }
                // 再次附加消息到新建的commitlog文件
                result = mappedFile.appendMessage(msg, this.appendMessageCallback);
                break;
            case MESSAGE_SIZE_EXCEEDED: // 消息或其属性超出限制返回失败
            case PROPERTIES_SIZE_EXCEEDED:
                beginTimeInLock = 0;
                return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, result);
            case UNKNOWN_ERROR:
                beginTimeInLock = 0;
                return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result);
            default:
                beginTimeInLock = 0;
                return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result);
        }

        // 计算消耗的时间
        eclipsedTimeInLock = this.defaultMessageStore.getSystemClock().now() - beginLockTimestamp;
        beginTimeInLock = 0;
    } finally {
        putMessageLock.unlock();
    }

    if (eclipsedTimeInLock > 500) {
        log.warn("[NOTIFYME]putMessage in lock cost time(ms)={}, bodyLength={} AppendMessageResult={}", eclipsedTimeInLock, msg.getBody().length, result);
    }

    // 如果附加消息成功并且没有创建新的commitlog文件则unlockMappedFile为null，否则为上一个commitlog文件，这里执行和mlock相反
    // 的操作munlock，使得操作系统能够回收和swap上一个commitlog文件
    if (null != unlockMappedFile && this.defaultMessageStore.getMessageStoreConfig().isWarmMapedFileEnable()) {
        this.defaultMessageStore.unlockMappedFile(unlockMappedFile);
    }

    // 运行到这说明附加成功了
    PutMessageResult putMessageResult = new PutMessageResult(PutMessageStatus.PUT_OK, result);

    // Statistics
    // 添加统计信息
    storeStatsService.getSinglePutMessageTopicTimesTotal(msg.getTopic()).incrementAndGet();
    storeStatsService.getSinglePutMessageTopicSizeTotal(topic).addAndGet(result.getWroteBytes());

    // 同步或异步刷盘
    handleDiskFlush(result, putMessageResult, msg);
    // 如果使用的是SYNC_MASTER同步更新slave，则等待slave更新消息
    handleHA(result, putMessageResult, msg);

    return putMessageResult;
}
```

`putMessage()`方法做了不少事，首先是对事务消息的处理，相关分析在笔记[如何实现事务消息](如何实现事务消息.md)，这里不再赘述。`putMessage()`方法还设置了一些传入的消息的属性，包括存储时间、bodyCRC、sysFlag等，这些信息最后都会和消息本体一块落盘。处理完消息对象后，`putMessage()`方法调用`this.mappedFileQueue.getLastMappedFile()`语句创建`MappedFile`对象，这个`MappedFile`对象对于消息存储的实现起到了最关键的作用，commitlog文件和consumeQueue文件都用到了`MappedFile`类，这里首先看rocketmq中关于commitlog的设计：

commitlog文件是消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容，消息内容不是定长的。单个文件大小默认1G，文件名长度为20位，左边补零，剩余为起始偏移量，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。消息主要是顺序写入日志文件，当文件满了，写入下一个文件。

上面提到的00000000000000000000和00000000001073741824文件在实际broker的存储路径默认是`~/store/commitlog`文件夹，broker运行时，随着消息不断的写入，该文件夹下会陆续创建若干文件，文件名的格式如上所示。rocketmq将commitlog文件夹的这种工作机制抽象了出来，提供了`CommitLog`对象表示commitlog文件夹，`CommitLog`对象持有`MappedFileQueue`对象，`MappedFileQueue`对象表示commitlog文件夹下的所有文件，通过`MappedFileQueue`对象，可以很方便的对commitlog文件夹内的文件进行操作，如创建和获取`MappedFile`对象、获取文件的最大和最小偏移量等。`MappedFile`对象表示的是某个commitlog文件夹内的文件，如上面的00000000000000000000和00000000001073741824文件，对commitlog内某个文件数据的读取与写入就是通过`MappedFile`对象实现的。`DefaultMessageStore`类实现消息存储就是通过`CommitLog`对象，而消息消费的过程和消息存储类似，对应的是`ConsumeQueue`类，这一块的分析在笔记[如何实现消息消费](如何实现消息消费.md)，这里不再赘述。

下面来看看`CommitLog`的`putMessage()`方法是如何通过`MappedFile`对象保存消息的。首先获取`MappedFile`对象的过程：
```java
public PutMessageResult putMessage(final MessageExtBrokerInner msg) {
    // 略

    MappedFile unlockMappedFile = null;
    // MappedFile实际上就是某个commitlog或consumeQueue文件，这里获取最新的commitlog文件
    MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile();

    // putMessageLock可能是ReentrantLock也可能是自选锁，根据配置决定，默认使用自旋锁
    putMessageLock.lock(); //spin or ReentrantLock ,depending on store config
    try {
        // 略

        // 判断这个最新的commitlog文件是否为空或是否已经写满
        if (null == mappedFile || mappedFile.isFull()) {
            // 新建一个MappedFile文件，即新建一个commitlog文件
            mappedFile = this.mappedFileQueue.getLastMappedFile(0); // Mark: NewFile may be cause noise
        }
        // 创建失败则报错
        if (null == mappedFile) {
            log.error("create mapped file1 error, topic: " + msg.getTopic() + " clientAddr: " + msg.getBornHostString());
            beginTimeInLock = 0;
            return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, null);
        }

        // 将消息附加到commitlog文件
        result = mappedFile.appendMessage(msg, this.appendMessageCallback);
    }
    // 略
}
```

首先通过`this.mappedFileQueue.getLastMappedFile()`语句获取最新的`MappedFile`对象，`MappedFile`对象文件名称由起始偏移量组成，所以这里相当于获取偏移量最大的`MappedFile`对象，`MappedFileQueue`对象的`getLastMappedFile()`方法代码：
```java
public MappedFile getLastMappedFile() {
    MappedFile mappedFileLast = null;

    while (!this.mappedFiles.isEmpty()) {
        try {
            mappedFileLast = this.mappedFiles.get(this.mappedFiles.size() - 1);
            break;
        } catch (IndexOutOfBoundsException e) {
            //continue;
        } catch (Exception e) {
            log.error("getLastMappedFile has exception.", e);
            break;
        }
    }

    return mappedFileLast;
}
```

上面用到的`mappedFiles`是`MappedFileQueue`对象中用于保存所有commitlog文件夹下文件对应的`MappedFile`对象的`CopyOnWriteArrayList`，最新的`MappedFile`对象就是list的最后一个元素。

在获取到`MappedFile`对象后，判断了该对象是否为空和是否满了，如果为空说明commitlog文件夹下没有文件，或者如果不为空但是文件已经写满了，这两种情况都需要创建一个新的文件，即创建一个新的`MappedFile`对象，这里先看如何判断`MappedFile`对象是否满了，对应的`isFull()`方法：
```java
public boolean isFull() {
    return this.fileSize == this.wrotePosition.get();
}
```

`wrotePosition`变量保存的是消息写入到`MappedFile`对象对应的文件的位置（实际上只是写入到buffer，还未commit和flush），所以当文件大小和写入位置相等时，就是`MappedFile`对象写满了。

下面来看`this.mappedFileQueue.getLastMappedFile(0)`语句是如何创建`MappedFile`对象的，对应的方法如下：
```java
public MappedFile getLastMappedFile(final long startOffset) {
    return getLastMappedFile(startOffset, true);
}

public MappedFile getLastMappedFile(final long startOffset, boolean needCreate) {
    long createOffset = -1;
    MappedFile mappedFileLast = getLastMappedFile();

    // 如果最新的MappedFile文件为空，则从startOffset开始，下面的计算方式保证createOffset等于mappedFileSize的整数倍
    if (mappedFileLast == null) {
        createOffset = startOffset - (startOffset % this.mappedFileSize);
    }

    // 如果MappedFile不为空并且已经满了则获取下一个创建的MappedFile的起始offset
    if (mappedFileLast != null && mappedFileLast.isFull()) {
        createOffset = mappedFileLast.getFileFromOffset() + this.mappedFileSize;
    }

    if (createOffset != -1 && needCreate) {
        // 根据offset获取即将创建的MappedFile文件的路径
        String nextFilePath = this.storePath + File.separator + UtilAll.offset2FileName(createOffset);
        // 预创建下一个文件的文件名称
        String nextNextFilePath = this.storePath + File.separator
            + UtilAll.offset2FileName(createOffset + this.mappedFileSize);
        MappedFile mappedFile = null;

        // 如果allocateMappedFileService不为空则使用allocateMappedFileService创建MappedFile。否则直接new一个
        if (this.allocateMappedFileService != null) {
            mappedFile = this.allocateMappedFileService.putRequestAndReturnMappedFile(nextFilePath,
                nextNextFilePath, this.mappedFileSize);
        } else {
            try {
                mappedFile = new MappedFile(nextFilePath, this.mappedFileSize);
            } catch (IOException e) {
                log.error("create mappedFile exception", e);
            }
        }

        if (mappedFile != null) {
            // 如果mappedFiles为空表示刚创建的MappedFile对象是第一个MappedFile文件
            if (this.mappedFiles.isEmpty()) {
                mappedFile.setFirstCreateInQueue(true);
            }
            this.mappedFiles.add(mappedFile);
        }

        return mappedFile;
    }

    return mappedFileLast;
}
```

上面的方法在最新的`MappedFile`对象不存在或`MappedFile`对象已经满的情况下都会执行创建`MappedFile`对象的逻辑，代码如下：
```java
// 根据offset获取即将创建的MappedFile文件的路径
String nextFilePath = this.storePath + File.separator + UtilAll.offset2FileName(createOffset);
// 预创建下一个文件的文件名称
String nextNextFilePath = this.storePath + File.separator
    + UtilAll.offset2FileName(createOffset + this.mappedFileSize);
MappedFile mappedFile = null;

// 如果allocateMappedFileService不为空则使用allocateMappedFileService创建MappedFile。否则直接new一个
if (this.allocateMappedFileService != null) {
    mappedFile = this.allocateMappedFileService.putRequestAndReturnMappedFile(nextFilePath,
        nextNextFilePath, this.mappedFileSize);
} else {
    try {
        mappedFile = new MappedFile(nextFilePath, this.mappedFileSize);
    } catch (IOException e) {
        log.error("create mappedFile exception", e);
    }
}
```

首先根据offset创建文件名，如00000000001073741824，另外除了即将创建了文件名，还创建了下一个需要被创建的文件名，如当前需要创建的文件为00000000001073741824，则`nextNextFilePath`是00000000002147483648，这么做的目的是为了预创建commitlog文件，这个在下面的分析就能看到。

在`allocateMappedFileService`对象不为空时创建`MappedFile`对象的任务由它完成，默认情况下`allocateMappedFileService`指向`AllocateMappedFileService`对象，所以默认情况下`MappedFile`对象由`AllocateMappedFileService`完成，其`putRequestAndReturnMappedFile()`方法代码如下：
```java
public MappedFile putRequestAndReturnMappedFile(String nextFilePath, String nextNextFilePath, int fileSize) {
    // 默认要创建nextFilePath和nextNextFilePath两个文件，所以这里默认假设允许创建2个请求
    int canSubmitRequests = 2;
    // 如果开启了"读写分离"的模式
    if (this.messageStore.getMessageStoreConfig().isTransientStorePoolEnable()) {
        // 如果开启了在无写buffer可用的情况下的快速失败配置
        if (this.messageStore.getMessageStoreConfig().isFastFailIfNoBufferInStorePool()
            && BrokerRole.SLAVE != this.messageStore.getMessageStoreConfig().getBrokerRole()) { //if broker is slave, don't fast fail even no buffer in pool
            // 可用的buffer数量减去等待创建的请求数量就是真正可用的buffer数量
            canSubmitRequests = this.messageStore.getTransientStorePool().availableBufferNums() - this.requestQueue.size();
        }
    }

    // AllocateRequest对象表示创建新文件的请求
    AllocateRequest nextReq = new AllocateRequest(nextFilePath, fileSize);
    // 将请求保存到map，以路径为key，request为值，如果nextFilePath在map中存在则nextPutOK为false，表示指定路径已经创建过request了
    // 由于下面的预创建机制，即预创建nextNextFilePath文件，所以除了第一次运行，基本上这里的nextPutOK都是false，这样每次调用
    // putRequestAndReturnMappedFile方法都不需要等待MappedFile文件创建完成，因为在上一次putRequestAndReturnMappedFile方法
    // 执行时就已经创建了
    boolean nextPutOK = this.requestTable.putIfAbsent(nextFilePath, nextReq) == null;

    if (nextPutOK) {
        // 如果允许创建的请求数量小于等于0则返回
        if (canSubmitRequests <= 0) {
            log.warn("[NOTIFYME]TransientStorePool is not enough, so create mapped file error, " +
                "RequestQueueSize : {}, StorePoolSize: {}", this.requestQueue.size(), this.messageStore.getTransientStorePool().availableBufferNums());
            // 不能创建则删除请求记录
            this.requestTable.remove(nextFilePath);
            return null;
        }
        // request保存到阻塞队列中，供mmapOperation方法执行创建文件的操作
        boolean offerOK = this.requestQueue.offer(nextReq);
        if (!offerOK) {
            log.warn("never expected here, add a request to preallocate queue failed");
        }
        canSubmitRequests--;
    }

    // nextNextFilePath为下一个将被创建的commitlog文件路径
    AllocateRequest nextNextReq = new AllocateRequest(nextNextFilePath, fileSize);
    boolean nextNextPutOK = this.requestTable.putIfAbsent(nextNextFilePath, nextNextReq) == null;
    // 这里相当于预创建下一个MappedFile的意思
    if (nextNextPutOK) {
        if (canSubmitRequests <= 0) {
            log.warn("[NOTIFYME]TransientStorePool is not enough, so skip preallocate mapped file, " +
                "RequestQueueSize : {}, StorePoolSize: {}", this.requestQueue.size(), this.messageStore.getTransientStorePool().availableBufferNums());
            this.requestTable.remove(nextNextFilePath);
        } else {
            boolean offerOK = this.requestQueue.offer(nextNextReq);
            if (!offerOK) {
                log.warn("never expected here, add a request to preallocate queue failed");
            }
        }
    }

    if (hasException) {
        log.warn(this.getServiceName() + " service has exception. so return null");
        return null;
    }

    // requestTable保存了所有创建MappedFile文件的请求，上面的代码在允许创建文件的情况下会将MappedFile文件的AllocateRequest对象
    // 添加到requestQueue这个阻塞队列中，AllocateMappedFileService类本身也是个线程，其run方法会不断的调用mmapOperation方法从
    // requestQueue获取请求并执行创建MappedFile文件的逻辑，创建完成后将创建结果更新AllocateRequest对象，这里获取nextFilePath对
    // 应的AllocateRequest对象，通过countDownLatch等待mmapOperation方法创建完nextFilePath文件
    AllocateRequest result = this.requestTable.get(nextFilePath);
    try {
        if (result != null) {
            // 等待commitlog文件创建完成
            boolean waitOK = result.getCountDownLatch().await(waitTimeOut, TimeUnit.MILLISECONDS);
            if (!waitOK) {
                log.warn("create mmap timeout " + result.getFilePath() + " " + result.getFileSize());
                return null;
            } else {
                // 创建成功删除AllocateRequest对象
                this.requestTable.remove(nextFilePath);
                // 返回被创建的MappedFile文件，此时requestTable中还存在nextNextFilePath对应的AllocateRequest对象，这里
                // 不需要等待nextNextFilePath创建完成，因为nextNextFilePath文件是预创建的，还没有被使用，等到需要时再从
                // requestTable获取对应的AllocateRequest对象并await即可
                return result.getMappedFile();
            }
        } else {
            log.error("find preallocate mmap failed, this never happen");
        }
    } catch (InterruptedException e) {
        log.warn(this.getServiceName() + " service has exception. ", e);
    }

    return null;
}
```

`putRequestAndReturnMappedFile()`方法没有指向真正的创建逻辑，而是为传入的文件名创建`AllocateRequest`对象，表示创建文件请求，之后将`AllocateRequest`对象保存到`requestQueue`队列中，最后通过`AllocateRequest`对象的`CountDownLatch`等待创建完成，真正执行创建逻辑的代码肯定在别的方法中，这个后面会分析，这里先看`putRequestAndReturnMappedFile()`方法做的其他工作。`putRequestAndReturnMappedFile()`方法首先用`canSubmitRequests`变量表示能够创建的请求数量，也就是`AllocateRequest`对象的数量，之后根据`MessageStoreConfig`的配置判断是否对`canSubmitRequests`变量进行更新，也就是是否限制能够创建的请求的数量，首先看`isTransientStorePoolEnable()`方法：
```java
public boolean isTransientStorePoolEnable() {
    return transientStorePoolEnable && FlushDiskType.ASYNC_FLUSH == getFlushDiskType()
        && BrokerRole.SLAVE != getBrokerRole();
}
```

上面的`transientStorePoolEnable`变量为true并且当前broker为异步刷盘且为master的情况下`isTransientStorePoolEnable()`方法返回true，`transientStorePoolEnable`变量为true时表示开启“读写分离”模式，这个“读写分离”模式的作用是，`MappedFile`对象初始化时除了创建一个通过mmap创建而来的`MappedByteBuffer`对象外，还会从broker的buffer池中申请一个堆外内存`ByteBuffer`，由`writeBuffer`属性持有。当需要写入数据时，不是直接调用写数据到`MappedByteBuffer`对象，而是写入到`writeBuffer`，`writeBuffer`中的数据由后台线程
